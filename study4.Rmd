# Study 4: Additional Data and Load Manipulation (Open Doors Day)


In this case study, we aimed to explore the following research questions: _Does the addition of new sources of data give more information (or confirm) about the orchestration load? Can we detect specific classroom interaction episodes that imply high (or low) cognitive load? Can we see differences between the orchestration load patterns of a teacher between sessions with (or without) a helper?_.

The **context** of the data gathering were four sessions of around 35-45 minutes each, with four different cohorts of 19-21 primery school students (aged 10-12 years old), in a classroom with several tabletop computers and a projector, enacting a lesson with exercises and a collaborative/competitive game using a tangible tabletop game, to learn about coordinate systems and basic geometric concepts like rotation and translation. During the lessons, the teacher was wearing a mobile eye-tracker, a single-electrode portable EEG device and a mobile phone in his pocket, which tracked the movements of the teacher with the phone's inertial sensors (accelerometers).

## Before starting: Data download and pre-process

First of all, we download the datasets for the study, which has been published in Zenodo: 

* TODO: Upload to zenodo and post here the link!

```{r, message=FALSE, warning=FALSE, echo=FALSE}
require(XML)
require(ggplot2)
require(reshape)
require(rjson)
require(plyr)
# We load the useful scripts and packages needed throughout the report
source("./lib/rollingWindows.R")
source("./lib/loadIndex.R")
source("./lib/extremeLoadExtraction.R")
source("./lib/aggregateEpisodeData.R")
source("./lib/multiplot.R")
source("./lib/outliers.R")
source('./lib/codeAnalyses.R')
source('./lib/generateVideoSnippetScript.R')
rootdir <- getwd()

# If not present already, download dataset study 4 and uncompress it to Study3/
setwd(paste(rootdir,"/data/study4",sep=""))
# if(!file.exists("ISL2014BASELINE-QuestionnaireData.zip") ||
#    !file.exists("ISL2015BASELINE-CodingData.zip") ||
#    !file.exists("ISL2014BASELINE-EyetrackingData.zip")){ #TODO: Add the other 3 files too!
#     download.file("https://zenodo.org/record/16551/files/ISL2014BASELINE-QuestionnaireData.zip", destfile="ISL2014BASELINE-QuestionnaireData.zip", method="curl")
#     unzip("ISL2014BASELINE-QuestionnaireData.zip")
#     download.file("https://zenodo.org/record/16551/files/ISL2015BASELINE-CodingData.zip", destfile="ISL2015BASELINE-CodingData.zip", method="curl")
#     unzip("ISL2015BASELINE-CodingData.zip")
#     download.file("https://zenodo.org/record/16551/files/ISL2014BASELINE-EyetrackingData.zip", destfile="ISL2014BASELINE-EyetrackingData.zip", method="curl")
#     unzip("ISL2014BASELINE-EyetrackingData.zip")
#     
#     #TODO: Update once the data is uploaded to zenodo
#     
# } 

# Now we should have the raw data files uncompressed in the data/study4 folder
```

Once we have the raw data from the eye-tracker (plus the video coding data generated by researchers), we pre-process it, mostly by aggregating the four load-related eyetracking metrics (pupil diameter mean, pupil diameter variation, saccade speed and number of fixations >500ms) into 10-second episodes, using a rolling window with 5-second slide between windows (see ```./lib/aggregateEpisodeData.R``` and ```./lib/rollingWindows.R``` files for details).

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
setwd(paste(rootdir,"/data/study4",sep=""))

# We do the preprocessing, which will generate a Rda file with the 10s
# window data, and will return the name of the file

sessions <-  c("JDC2015-Session1","JDC2015-Session2","JDC2015-Session3","JDC2015-Session4")

##############################################
# Loading and preprocessing of video code data (overall)
annotationsData <- data.frame()

if(!file.exists(paste(rootdir,"/data/study4/cleanAnnotationData.Rda",sep=""))){
    
    for (session in sessions){
    
        # We load the video coding data
        # Parse the XML
        rawXML <- xmlParse(paste(rootdir,"/data/study4/",session,"-videoCoding.eaf",sep=""))
        parsedXML <- xmlToList(rawXML)
        # Extract the time markers for the annotations, to be used later
        annotationTimes <- data.frame(matrix(unlist(parsedXML[["TIME_ORDER"]]), nrow=length(parsedXML[["TIME_ORDER"]]), byrow=T))
        names(annotationTimes) <- c("TIME_SLOT_ID", "TIME_VALUE")
        
        # We get the data for each Annotation Tier
        comments <- data.frame(start=numeric(), end=numeric(), annotation=character())
        social <- data.frame(start=numeric(), end=numeric(), annotation=character())
        experimental <- data.frame(start=numeric(), end=numeric(), annotation=character())
        activity <- data.frame(start=numeric(), end=numeric(), annotation=character())
        recording <- data.frame(start=numeric(), end=numeric(), annotation=character())
        for (tier in parsedXML[names(parsedXML) %in% "TIER"]){
            if(class(tier) != "list") next; #If it is an empty tier, it will not be a list, we just pass
            
            tierName <- tier$.attrs["TIER_ID"]
            
            if(tierName=="Comments"){# The Comments tier
                for(annot2 in tier[names(tier) %in% "ANNOTATION"]){
                    annot <- annot2$ALIGNABLE_ANNOTATION
                    annotation <- data.frame(start=as.numeric(as.character(annotationTimes[annotationTimes$TIME_SLOT_ID==annot$.attrs["TIME_SLOT_REF1"],"TIME_VALUE"])), 
                                             end=as.numeric(as.character(annotationTimes[annotationTimes$TIME_SLOT_ID==annot$.attrs["TIME_SLOT_REF2"],"TIME_VALUE"])),
                                             annotation=annot$ANNOTATION_VALUE)
                    comments <- rbind(comments,annotation)
                }
            }
            
            if(tierName=="Recording markers"){# Recording markers tier
                for(annot2 in tier[names(tier) %in% "ANNOTATION"]){
                    annot <- annot2$ALIGNABLE_ANNOTATION
                    annotation <- data.frame(start=as.numeric(as.character(annotationTimes[annotationTimes$TIME_SLOT_ID==annot$.attrs["TIME_SLOT_REF1"],"TIME_VALUE"])), 
                                             end=as.numeric(as.character(annotationTimes[annotationTimes$TIME_SLOT_ID==annot$.attrs["TIME_SLOT_REF2"],"TIME_VALUE"])),
                                             annotation=annot$ANNOTATION_VALUE)
                    recording <- rbind(recording,annotation)
                }
            }
        
            if(tierName=="Activity"){# Activities tier
                for(annot2 in tier[names(tier) %in% "ANNOTATION"]){
                    annot <- annot2$ALIGNABLE_ANNOTATION
                    annotation <- data.frame(start=as.numeric(as.character(annotationTimes[annotationTimes$TIME_SLOT_ID==annot$.attrs["TIME_SLOT_REF1"],"TIME_VALUE"])), 
                                             end=as.numeric(as.character(annotationTimes[annotationTimes$TIME_SLOT_ID==annot$.attrs["TIME_SLOT_REF2"],"TIME_VALUE"])),
                                             annotation=annot$ANNOTATION_VALUE)
                    activity <- rbind(activity,annotation)
                }
            }
            
            if(tierName=="Social plane"){# social plane tier
                for(annot2 in tier[names(tier) %in% "ANNOTATION"]){
                    annot <- annot2$ALIGNABLE_ANNOTATION
                    annotation <- data.frame(start=as.numeric(as.character(annotationTimes[annotationTimes$TIME_SLOT_ID==annot$.attrs["TIME_SLOT_REF1"],"TIME_VALUE"])), 
                                             end=as.numeric(as.character(annotationTimes[annotationTimes$TIME_SLOT_ID==annot$.attrs["TIME_SLOT_REF2"],"TIME_VALUE"])),
                                             annotation=annot$ANNOTATION_VALUE)
                    social <- rbind(social,annotation)
                }
            }
            
            if(tierName=="Experimental part"){# Experimental part tier
                for(annot2 in tier[names(tier) %in% "ANNOTATION"]){
                    annot <- annot2$ALIGNABLE_ANNOTATION
                    annotation <- data.frame(start=as.numeric(as.character(annotationTimes[annotationTimes$TIME_SLOT_ID==annot$.attrs["TIME_SLOT_REF1"],"TIME_VALUE"])), 
                                             end=as.numeric(as.character(annotationTimes[annotationTimes$TIME_SLOT_ID==annot$.attrs["TIME_SLOT_REF2"],"TIME_VALUE"])),
                                             annotation=annot$ANNOTATION_VALUE)
                    experimental <- rbind(experimental,annotation)
                }
            }
            
        }
    
        #Add tier field to all data frames, and put them together, and add the session field too
        comments$tier = "Comments"
        recording$tier = "Recording"
        activity$tier = "Activity"
        social$tier = "Social"
        experimental$tier = "Experimental"
        sessionAnnotations = rbind(comments,recording,activity,social,experimental)
        sessionAnnotations$session = session
        # Join all sessions in a single dataframe
        if(nrow(annotationsData)==0) annotationsData = sessionAnnotations
        else annotationsData = rbind(annotationsData,sessionAnnotations)
    
    }
    
    save(annotationsData, file = paste(rootdir,"/data/study4/cleanAnnotationData.Rda",sep=""))
        
    
}else{
    annotationsData <- get(load(paste(rootdir,"/data/study4/cleanAnnotationData.Rda",sep="")))
}
# annotationsData now has the clean video coding data

datadir <- paste(rootdir,"/data/study4",sep="")

####################################################################
# Preprocessing of the teacher tracker files (from JSON to a data frame with the beacon and accel x,y,z)
trackerData <- data.frame()
if(!file.exists(paste(rootdir,"/data/study4/cleanTrackerData.Rda",sep=""))){

        for (session in sessions){

            sessionTrackerData <- data.frame(accelerationX=numeric(),
                  accelerationY=numeric(),
                  accelerationZ=numeric(),
                  timestamp=numeric(),
                  beaconID=character(),
                  proximity=numeric(),
                  distance=numeric(),
                  rssi=numeric())

            # We get the tracker files for this session
            filenames <- dir(datadir)[grepl(session,dir(datadir))]
            filenames <- filenames[grepl("-teacherTracker",filenames)]

            for(file in filenames){# For each file...
                
                lines <- paste(readLines(paste(datadir,"/",file,sep="")),collapse="")
                # Retouch it a bit so that it is proper json
                lines <- gsub("[]", "", lines, fixed=T)
                lines <- gsub("][", ",", lines, fixed=T)
                # We parse the json
                json_data <- fromJSON(lines)
                df <- ldply(json_data, data.frame)
                
                if(ncol(df)!=ncol(sessionTrackerData)){# If our resulting data frame does not have all columns, we add them (for the rbind to work)
                    dummy <- data.frame(accelerationX=numeric(), accelerationY=numeric(), accelerationZ=numeric(),
                                           timestamp=numeric(), beaconID=character(), proximity=numeric(), 
                                           distance=numeric(), rssi=numeric())
                    df <- merge(df,dummy,all = T)
                }
                
                sessionTrackerData <- rbind(sessionTrackerData,df)
                
            }
            
            sessionTrackerData$session <- session
            if(nrow(trackerData)==0) trackerData <- sessionTrackerData
            else trackerData <- rbind(trackerData,sessionTrackerData)
        }
        
        # We remove duplicate entries, there can still be entries with the same timestamp, but they will be either an accelerometer or a beacon entry
        trackerData <- unique(trackerData)
        
        save(trackerData, file = paste(rootdir,"/data/study4/cleanTrackerData.Rda",sep=""))
    
}else{
    trackerData <- get(load(paste(rootdir,"/data/study4/cleanTrackerData.Rda",sep="")))
}
# trackerData now has the clean teacher tracker/accelerometer data


################################################################
# Preprocessing of the EEG files: for now, only use theta band
# We get the start/end times of the EEG recording of each session 
# (manually, from the annotations files -- in seconds, as the EEG files times are in seconds since start of recording)
eegtimes <- data.frame(start=c(66.567,0,52.600,0),end=c(2371.767,2278.900,2155.200,1557.400),session=sessions)
eegdata <- data.frame()
if(!file.exists(paste(datadir,"/cleanEEGData.Rda",sep=""))){
    for (session in sessions){
        # We get the EEG file filename
        filepattern <- paste(session,"-EEG",sep="")
        filename <- dir(datadir)[grepl(filepattern,dir(datadir))]
        eegsession <- read.csv2(file = paste(datadir,"/",filename,sep=""))
        eegsession <- eegsession[,1:13]
        eegsession$session <- session
        #Time (s);Electrode;Attention;Meditation;Delta;Theta;Low Alpha;High Alpha;Low Beta;High Beta;Low Gamma;Mid Gamma;Blink Strength
        eegsession$Time..s. <- as.numeric(as.character(eegsession$Time..s.))
        eegsession$Electrode <- as.numeric(as.character(eegsession$Electrode))
        eegsession$Attention <- as.numeric(as.character(eegsession$Attention))
        eegsession$Meditation<- as.numeric(as.character(eegsession$Meditation))
        eegsession$Delta<- as.numeric(as.character(eegsession$Delta))
        eegsession$Theta<- as.numeric(as.character(eegsession$Theta))
        eegsession$Low.Alpha<- as.numeric(as.character(eegsession$Low.Alpha))
        eegsession$High.Alpha<- as.numeric(as.character(eegsession$High.Alpha))
        eegsession$Low.Beta<- as.numeric(as.character(eegsession$Low.Beta))
        eegsession$High.Beta<- as.numeric(as.character(eegsession$High.Beta))
        eegsession$Low.Gamma<- as.numeric(as.character(eegsession$Low.Gamma))
        eegsession$Mid.Gamma<- as.numeric(as.character(eegsession$Mid.Gamma))
        eegsession$Blink.Strength<- as.numeric(as.character(eegsession$Blink.Strength))
        if(nrow(eegdata)==0) eegdata <- eegsession
        else eegdata <- rbind(eegdata,eegsession)
    }
    eegdata$session <- factor(eegdata$session)
    save(eegdata,file = paste(datadir,"/cleanEEGData.Rda",sep=""),compress=TRUE)
} else {
    eegdata <- get(load(paste(datadir,"/cleanEEGData.Rda",sep="")))
}
#eegdata now has the the clean EEG data

###########################################
# Merging and aggregation of the different data sources of load and video annotations in 10-second episode
# We get the time period of interest from the annotation file
initendtimes <- annotationsData[annotationsData$tier=="Recording" 
                                & annotationsData$annotation == "Recording", c("start","end","session")]

# Aggregation of the eyetracking data
eyedata <- aggregateEpisodeData(sessions, datadir=paste(rootdir,"/data/study4",sep=""), initendtimes=initendtimes, SEPARATOR=";") # For this study the raw data is semicolon-separated, at least the fixation/saccades!
eyedata <- eyedata[,c(1:5,12)] # We select only the load-related metrics

# We calculate the video coding values for the same windows
videocodedata <- aggregateVideoCodingData(sessions, datadir=paste(rootdir,"/data/study4",sep=""),
                                          initendtimes=initendtimes)

# Merge video codes and eyetracking        
totaldata <- merge(eyedata,videocodedata,by=c("time","session"),all=T)
totaldata <- totaldata[order(totaldata$session,totaldata$time),]
totaldata$value.Experimental <- factor(totaldata$value.Experimental)
totaldata$value.Social <- factor(totaldata$value.Social)
totaldata$value.Activity <- factor(totaldata$value.Activity)
        
# We aggregate the EEG data in rolling window episodes (for now, only Theta and attention)
agEEGdata <- aggregateEEGData(eegdata, eegtimes)

# We merge and align EEG with the previous eyetrack/videocode data
newtotaldata <- data.frame()
for(session in sessions){
    sessiondata <- totaldata[totaldata$session==session,]
    sessioneeg <- agEEGdata[agEEGdata$session==session,]
    

    # We know the mistmatch between EEG and eyetrack data episodes comes from 
    # the late EEG start in session 4, so we aggregate the EEG data accordingly
    if(nrow(sessiondata)==nrow(sessioneeg)){
        #Ensure that the episodes are aligned
        sessiondata <- sessiondata[order(sessiondata$time),]
        sessioneeg <- sessioneeg[order(sessioneeg$time),]
        
        sessiondata$value.Electrode <- sessioneeg$value.Electrode
        sessiondata$value.Attention <- sessioneeg$value.Attention
        sessiondata$value.Meditation <- sessioneeg$value.Meditation
        sessiondata$value.Delta <- sessioneeg$value.Delta
        sessiondata$value.Theta <- sessioneeg$value.Theta
        sessiondata$value.Low.Alpha <- sessioneeg$value.Low.Alpha
        sessiondata$value.High.Alpha <- sessioneeg$value.High.Alpha
        sessiondata$value.Low.Beta <- sessioneeg$value.Low.Beta
        sessiondata$value.High.Beta <- sessioneeg$value.High.Beta
        sessiondata$value.Low.Gamma <- sessioneeg$value.Low.Gamma
        sessiondata$value.Mid.Gamma <- sessioneeg$value.Mid.Gamma
        sessiondata$value.Blink.Strength <- sessioneeg$value.Blink.Strength
    }else{
        num <- nrow(sessiondata)-nrow(sessioneeg)
        sessiondata <- sessiondata[order(sessiondata$time),]
        sessioneeg <- sessioneeg[order(sessioneeg$time),]
        sessiondata$value.Electrode <- c(rep(NA,num),sessioneeg$value.Electrode)
        sessiondata$value.Attention <- c(rep(NA,num),sessioneeg$value.Attention)
        sessiondata$value.Meditation <- c(rep(NA,num),sessioneeg$value.Meditation)
        sessiondata$value.Delta <- c(rep(NA,num),sessioneeg$value.Delta)
        sessiondata$value.Theta <- c(rep(NA,num),sessioneeg$value.Theta)
        sessiondata$value.Low.Alpha <- c(rep(NA,num),sessioneeg$value.Low.Alpha)
        sessiondata$value.High.Alpha <- c(rep(NA,num),sessioneeg$value.High.Alpha)
        sessiondata$value.Low.Beta <- c(rep(NA,num),sessioneeg$value.Low.Beta)
        sessiondata$value.High.Beta <- c(rep(NA,num),sessioneeg$value.High.Beta)
        sessiondata$value.Low.Gamma <- c(rep(NA,num),sessioneeg$value.Low.Gamma)
        sessiondata$value.Mid.Gamma <- c(rep(NA,num),sessioneeg$value.Mid.Gamma)
        sessiondata$value.Blink.Strength <- c(rep(NA,num),sessioneeg$value.Blink.Strength)
        
    }
    
    if(nrow(newtotaldata)==0) newtotaldata <- sessiondata
    else newtotaldata <- rbind(newtotaldata,sessiondata)
}

totaldata <- newtotaldata
    
# Aggregation of the accelerometer data for the episodes (for now, only average and SD for each component)
# We get the start/end times of the accelerometer recording of each session 
# (manually, from the annotations files -- in milliseconds)
newtotaldata <- data.frame()
accdata <- trackerData[complete.cases(trackerData$accelerationX),]
accdata <- accdata[order(accdata$timestamp),]
acctimes <- data.frame(start=c(0,3300,0,0),end=c(2305200,2282200,2102600,1901500),session=sessions)
agAccdata <- aggregateAccelerometerDataWithJerk(accdata, acctimes)
agAccdata <- agAccdata[order(agAccdata$time),] # We will ignore these timestamps, as we will aggregate them to the master table that uses the eyetracking ones
for(session in sessions){
    sessiondata <- totaldata[totaldata$session == session,]
    sessiondata <- sessiondata[order(sessiondata$time),]
    
    sessiondata$value.X.Mean <- agAccdata[agAccdata$session == session , "value.X.Mean"]
    sessiondata$value.X.SD <- agAccdata[agAccdata$session == session , "value.X.SD"]
    sessiondata$value.Y.Mean <- agAccdata[agAccdata$session == session , "value.Y.Mean"]
    sessiondata$value.Y.SD <- agAccdata[agAccdata$session == session , "value.Y.SD"]
    sessiondata$value.Z.Mean <- agAccdata[agAccdata$session == session , "value.Z.Mean"]
    sessiondata$value.Z.SD <- agAccdata[agAccdata$session == session , "value.Z.SD"]
    sessiondata$value.Jerk.Mean <- agAccdata[agAccdata$session == session , "value.Jerk.Mean"]
    sessiondata$value.Jerk.SD <- agAccdata[agAccdata$session == session , "value.Jerk.SD"]

    if(nrow(newtotaldata)==0) newtotaldata <- sessiondata
    else newtotaldata <- rbind(newtotaldata,sessiondata)
}
totaldata <- newtotaldata

cleandatafile <- "study4ProcessedData.Rda"
save(totaldata, file=cleandatafile)

```

### A: From samples to episodes

We first calculate the _coarse load index_ (how many measures are over the median) and the _fine load index_ (average of percentiles of the different load metrics), and we plot them for each session

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=3, fig.width=8}
setwd(paste(rootdir,"/data/study4",sep=""))
totaldata <- get(load(cleandatafile))[,c(1:9,11,14,28,29)] # We load the data, getting only the load-related and coding columns

# In case there are missing values (sp. in the saccade speed, but also others), we remove them
totaldata <- totaldata[complete.cases(totaldata$value.Sac) &
                           complete.cases(totaldata$value.Theta) &
                           complete.cases(totaldata$value.Jerk.Mean),]
# We crop outliers in the saccade speed. They tend to throw off the HMM and PCA calculations
#countOutliers(totaldata$value.Sac,coef = 10, method="iqr") # IQR is quite small (0.06), but there are quite a few samples outside this range, we make it 10xIQR
totaldata$value.Sac <- replaceOutliers(totaldata$value.Sac,valueNA = F,coef = 10, method="iqr")

loaddata <- calculateCoarseFineLoadIndex(totaldata,c(3:6,10,12,13),normalize=T, inversecols = 11) # We ensure that the values are normalized for those of the first window in which little load is assumed (just putting the eyetracker on)

# We plot the loads for each session, along with some smoothing
for(session in sessions){
    sessiondata <- loaddata[loaddata$session==session,]
    p1 <- ggplot(sessiondata, aes(x=time, y=CoarseLoad, col=CoarseLoad)) + 
            ggtitle(paste("Coarse Load Index ",session,sep="")) + 
            geom_line(size=1) + stat_smooth(method="loess",span=0.1,se=F) +
            #theme(axis.text.x = element_text(size=18),plot.title=element_text(size=20, face="bold"),axis.title=element_text(size=18),panel.background = element_rect(fill = 'white')) +
            theme(panel.background = element_rect(fill = 'white')) +
            scale_color_gradient(low="green",high="red")
    print(p1)

    p2 <- ggplot(sessiondata, aes(x=time, y=FineLoad, col=FineLoad)) + 
            ggtitle(paste("Fine Load Index ",session,sep="")) + 
            geom_line(size=1) + stat_smooth(method="loess",span=0.1,se=F) +
            #theme(axis.text.x = element_text(size=18),plot.title=element_text(size=20, face="bold"),axis.title=element_text(size=18),panel.background = element_rect(fill = 'white')) +
            theme(panel.background = element_rect(fill = 'white')) +
            scale_color_gradient(low="green",high="red")
    print(p2)
}
```

We can also see whether there is any difference in the overall load regarding the **load manipulation** done (with helper (C1, session 1 and 4), and without help (C2, session 2 and 3)):

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=3, fig.width=8}
expdata <- loaddata[loaddata$value.Experimental=="C1" | loaddata$value.Experimental=="C2", ]
expdata$value.Experimental<- factor(expdata$value.Experimental)
g1 <- ggplot(data = expdata, mapping = aes(value.Experimental,FineLoad))+geom_boxplot(aes(fill=value.Experimental))+geom_jitter()
print(g1)

exptab <- xtabs(~expdata$CoarseLoad+expdata$value.Experimental)
chisq.test(exptab)
```

We see that, at the level of overall orchestration load (fine or coarse), **we cannot distinguish** the equivalent parts of the lesson that had a helper from those that did not.


### B: Exploring the structure of the sensor (episode) load data 

First we do a Principal Component analysis to see what dimensions are there within these 4 load-related signals:

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=5, fig.width=5}

library(FactoMineR)

# Overall for the three sessions
res.pca = PCA(loaddata[, c(3:6,10,11,12,13)], scale.unit=TRUE, ncp=5, graph=F)
plot.PCA(res.pca, axes=c(1, 2), choix="var", title="Overall data")
plot.PCA(res.pca, axes=c(3, 4), choix="var", title="Overall data")
loaddata$PhysicalLoadDim = res.pca$ind$coord[,1]
loaddata$OverallCognitiveLoadDim = res.pca$ind$coord[,2]
loaddata$EEGInvAttentionLoadDim = res.pca$ind$coord[,3]
loaddata$FixVsSacLoadDim = res.pca$ind$coord[,4]

# We now do it per session, to see if the teacher has different patterns... Nope, they are practically identical
# for(session in sessions){
#      sessiondata <- loaddata[loaddata$session==session,]
#      res.pca = PCA(loaddata[, c(3:6,10,11,12)], scale.unit=TRUE, ncp=5, graph=F)
#      print(plot.PCA(res.pca, axes=c(1, 2), choix="var",title = paste("Session",session)))
# }

```

Interestingly, by looking at the first 4 dimensions of the variance in the data (since we now have 8 load-related metrics), now we can see that some of the dimensions are coincident with those of study 1 (the teacher was the same, and the technological setting was similar): (1) There is a (new) dimension of _physical load_ (mostly from accelerometer data), which seems quite unrelated to the other cognitive dimensions; (2) There is the dimension led by pupil diameter measures, which now we see is somewhat supported by the inverse of the EEG theta signal, and thus we can conceive it as our best guess for the _overall cognitive load_; (3) A (new) dimension of data, mostly from the EEG source, in which attention is opposed to theta, thus making the dimension an _inverse attention/focus_ one; (4) We have the dimension, already observed in study 1, in which long _fixation-based load is opposed to saccadic speed load_.


We can also see whether there is any difference in the overall load regarding the **load manipulation** done (with helper (C1, session 1 and 4), and without help (C2, session 2 and 3)):

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=3, fig.width=8}
# We plot the experimental varieties across the four load dimensions
exp.res.pca = PCA(loaddata[, c(3:6,10,11,12,13,7)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=9)
plot.PCA(exp.res.pca, axes=c(1, 2), choix="ind", habillage=9, invisible="ind")
plot.PCA(exp.res.pca, axes=c(3, 4), choix="ind", habillage=9, invisible="ind")

# We check whether the differences in dim 3 and dim 4 are statistically significant (t.test)
with(loaddata, t.test(EEGInvAttentionLoadDim[value.Experimental=="C1"],EEGInvAttentionLoadDim[value.Experimental=="C2"]))
with(loaddata, t.test(FixVsSacLoadDim[value.Experimental=="C1"],FixVsSacLoadDim[value.Experimental=="C2"]))

```

We see that, in terms of physical load, the sessions without help had slightly higher load (which makes sense, as the teacher only had to cover half of the groups), albeit in terms of cognitive load they are practically identical (which may make sense given that the activities the teacher was doing were very similar). The differences between the two conditions are more clear in the attention dimension (the teacher was more attentive in the sessions with a helper), but especially in the fixation vs. saccade speed dimension (the teacher had to cover more ground with the gaze in the sessions without help).

It is also interesting how the common parts of the lesson, where the helper was irrelevant (e.g., during explanations), were much higher overall cognitive load.


To explore the temporal structure of these load-related sensor signals, we train a Hidden Markov Model, with 4 states using the load-related signals as observables:

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=5, fig.width=5}
library(depmixS4)

numstates <- 4

# Overall
set.seed(1)
#set up the HMM model
mod <- depmix(list(value.Mean~1,value.SD~1,value.Sac~1,value.Fix~1,value.Jerk.Mean~1,value.Jerk.SD~1,value.Theta~1,value.Attention~1), data=loaddata, nstates=numstates, family=list(gaussian(),gaussian(),gaussian(),poisson(),gaussian(),gaussian(),gaussian(),gaussian()),ntimes=summary(as.factor(loaddata$session)), verbose=F)
#fit the model 
f <- fit(mod, verbose=F)
#check to see how the state transtion matricies and process mean/sd matches our sample data
summary(f)
#get the estimated state for each timestep 
esttrans <- posterior(f)
loaddata$MMstate4 <- esttrans[,1]
#plot(1:nrow(loaddata), esttrans[,1], type='p', col=as.factor(loaddata$session), main=paste('Estimated state',numstates))

loaddata$MMstate4 <- factor(loaddata$MMstate4)
hmmloadtab <- xtabs(~CoarseLoad+MMstate4,data=loaddata)
hmmloadtab
chisq.test(hmmloadtab)$p.value
chisq.test(hmmloadtab)$residuals

g1 <- ggplot(data = loaddata, mapping = aes(MMstate4, FineLoad))+geom_boxplot(aes(fill=MMstate4))+geom_jitter()
print(g1)
# We can also plot the states with regard to the two load dimensions from the PCA
g2 <- ggplot(data = loaddata, mapping = aes(PhysicalLoadDim,OverallCognitiveLoadDim)) + geom_point(aes(col=MMstate4))
print(g2)
g2b <- ggplot(data = loaddata, mapping = aes(EEGInvAttentionLoadDim,FixVsSacLoadDim)) + geom_point(aes(col=MMstate4))
print(g2b)

levels(loaddata$MMstate4) <- c("HiPhysicalLoadState","LowPhysicalLoadState","MidHiCognitiveLoadState","MidLowCognitiveLoadState")


```

As we can see, State 1 seems to be a high load state, especially physical load; State 2 is a clearly low-load state (especially low physical load); State 3 is a medium-high load state, with high overall cognitive load; finally, State 4 is a medium-low load, with low overall cognitive load. 

However, the states do not do much separation in terms of the other two load dimensions identified. Maybe we need to increase the number of states to see such separation.

* State 1: high-load, especially physical load
* State 2: low-load, especially physical load
* State 3: mid-high load, high cognitive load
* State 4: mid-low load, low cognitive load

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=3, fig.width=8}
expdata <- loaddata[loaddata$value.Experimental=="C1" | loaddata$value.Experimental=="C2", ]
expdata$value.Experimental<- factor(expdata$value.Experimental)
exptab <- xtabs(~expdata$MMstate4+expdata$value.Experimental)
chisq.test(exptab)
```

Looking at this 4-state model with respect to the **load manipulation** done during the sessions, we see that it does not really manage to catch the difference between the sessions (which is to be expected, given that this model mostly takes dimensions 1 and 2 into account).



```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=5, fig.width=5}
numstates <- 8

# Overall
set.seed(1)
#set up the HMM model
mod <- depmix(list(value.Mean~1,value.SD~1,value.Sac~1,value.Fix~1,value.Jerk.Mean~1,value.Jerk.SD~1,value.Theta~1,value.Attention~1), data=loaddata, nstates=numstates, family=list(gaussian(),gaussian(),gaussian(),poisson(),gaussian(),gaussian(),gaussian(),gaussian()),ntimes=summary(as.factor(loaddata$session)), verbose=F)
#fit the model 
f <- fit(mod, verbose=F)
#check to see how the state transtion matricies and process mean/sd matches our sample data
summary(f)
#get the estimated state for each timestep 
esttrans <- posterior(f)
loaddata$MMstate8 <- esttrans[,1]
#plot(1:nrow(loaddata), esttrans[,1], type='p', col=as.factor(loaddata$session), main=paste('Estimated state',numstates))

loaddata$MMstate8 <- factor(loaddata$MMstate8)
hmmloadtab <- xtabs(~CoarseLoad+MMstate8,data=loaddata)
hmmloadtab
chisq.test(hmmloadtab)$p.value
chisq.test(hmmloadtab)$residuals

g1 <- ggplot(data = loaddata, mapping = aes(MMstate8, FineLoad))+geom_boxplot(aes(fill=MMstate8))+geom_jitter()
print(g1)
# We can also plot the states with regard to the two load dimensions from the PCA
g2 <- ggplot(data = loaddata, mapping = aes(PhysicalLoadDim,OverallCognitiveLoadDim)) + geom_point(aes(col=MMstate8))
print(g2)
# Another way to see it in the PCA space
hmm.res.pca = PCA(loaddata[, c(3:6,10,11,12,13,45)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=9)
plot.PCA(hmm.res.pca, axes=c(1, 2), choix="ind", habillage=9, invisible="ind")

g2b <- ggplot(data = loaddata, mapping = aes(EEGInvAttentionLoadDim,FixVsSacLoadDim)) + geom_point(aes(col=MMstate8)) #+ xlim(-1,1) + ylim(-1,1)
print(g2b)
# Another way to see it in the PCA space
plot.PCA(hmm.res.pca, axes=c(3, 4), choix="ind", habillage=9, invisible="ind")

#State 1/2 seems to be mid/hi load, state 3 is mid load, state 4 is low-load
levels(loaddata$MMstate8) <- c("HiCognitiveLoadState","MidHiPhysicalLowCogLoadState","MidLowPhysCogLoadState","MidLowPhysHiCogLoadState","HiPhysicalFixLoadState","MidLoadState","MidHiCogLowPhysLoadState","LowLoadState")


```

As we can see, State 1 and 5 seems to be a high load states; State 3 and 4 are mid-low load states; states 2,6,7 are mid-high load states. State 8 is clearly the low-load state.

Looking at the different dimensions of orchestration load, we see that again the 8 states do not separate along the third and fourth load dimensions as well as the first two, but still quite distinguishable among each other:

* State 1: high-load, especially high overall cognitive load but lower attention
* State 2: mid-high-load, high physical but low cognitive load, higher attention
* State 3: mid-low load, low physical and cognitive load, higher attention and saccade speed
* State 4: mid-low load, low physical but high cognitive load, higher long fixations
* State 5: high load, highest physical load and long fixations
* State 6: mid load, average in all dimensions
* State 7: mid-high load, especially cognitive and low physical, lower atention
* State 8: low load, with higher attention and saccade speeds


```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=3, fig.width=8}
expdata <- loaddata[loaddata$value.Experimental=="C1" | loaddata$value.Experimental=="C2", ]
expdata$value.Experimental<- factor(expdata$value.Experimental)
exptab <- xtabs(~expdata$MMstate8+expdata$value.Experimental)
chisq.test(exptab)
```

Looking at this 8-state model with respect to the **load manipulation** done during the sessions, we see that it does not really catch the difference between the sessions. This may indicate that the HMM states catch mostly load related to _what the teacher does_, rather than the memory/modelling of the student state (which is the main difference between the sessions with and without helper) ... to be confirmed by the behavioral analyses below.



### C: Subjective episode analysis

This part was not done in this study, as the researcher was the main teacher, and might have had assumptions about what each episode's load should be (thus, his subjective data might have been biased)

### D: Behavioral episode analysis

In this case, to see how valid our "extreme load sampling" coding was, we manually coded of the subjective video feed by a researcher, using E-LAN software (see the ```JDC2015-Session*-videoCoding.eaf``` file). Due to the increased cost of this manual process, we only coded the teacher activity and social plane of interaction, _not_ the main gaze focus (as that may change much more often).

In the preprocessing, we have aggregated the code counts for each of these dimensions, to bridge from the episode-level analysis to have an idea of what kind of episodes are often high or low (coarse/fine) load. Also, comparisons with fine load, and the PCA and HMM dimensions of load data are made.

#### Activity dimension


```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# Overall behavioral analyses
# ACTIVITY
behdata <- loaddata[(!is.na(loaddata$value.Activity)),]
behdata$value.Activity <- factor(behdata$value.Activity)
# chi-squared test and counts/residuals table for teacher activity
tabAct <- table(behdata$CoarseLoad,behdata$value.Activity)
chisq.test(tabAct)
tabAct
chisq.test(tabAct)$residuals

# Plotting against the FineLoad confirms the trends of CoarseLoad (even with its tendency towards the mean)
g1 <- ggplot(loaddata[!is.na(loaddata$value.Activity),],aes(value.Activity,FineLoad)) + geom_boxplot(aes(fill=value.Activity)) + geom_jitter(aes(col=session))
print(g1)
# Another way of seeing this, in the PCA diagram
act.res.pca = PCA(loaddata[, c(3:6,10:13, 9)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=9)
plot.PCA(act.res.pca, axes=c(1, 2), choix="ind", habillage=9, invisible="ind")
plot.PCA(act.res.pca, axes=c(3, 4), choix="ind", habillage=9, invisible="ind")

# Comparison against the HMM states of load -- The states are different for each session, almost!
# hmmActTab <- xtabs(~value.Activity+MMstate4, data=behdata)
# chisq.test(hmmActTab)
# hmmActTab
# chisq.test(hmmActTab)$residuals
hmmActTab <- xtabs(~value.Activity+MMstate8, data=behdata)
chisq.test(hmmActTab)
hmmActTab
chisq.test(hmmActTab)$residuals

```

Looking at the overall data, we find that **Activity** seems related to the coarse load, and we see that REPairs are clearly the activity that loads the teacher less, with TDT being the one that loads the teacher most, overall.

However, looking into the PCA load dimensions, we see more clearly the separation among the different activities: REPairs are low physical and cognitive load (and heavier on saccade speed), while EXPlanations are low-physical but high-cognitive load; QUEstioning and MONitoring are medium physical load, but the first is higher cognitive load, and the latter is lower cognitive load. Also, it is interesting that MON and REP are in the higher-attention side, while QUE and EXP are lower in the attention-based load.

Looking at the HMM (8-state) model, we find that certain activities are clearly represented in some states: TDT tends to be MidLoadState or MidHiCogLowPhysLoadState; EXP seems to be in the high-cognitive load states like MidLowPhysHiCogLoadState, MidHiCogLowPhysLoadState; so is QUE (MidLowPhysHiCogLoadState, HiCognitiveLoadState); MON is more mid-range (MidHiPhysicalLowCogLoadState, MidLoadState), while REP is clearly in the low-load states (MidLowPhysCogLoadState, LowLoadState).

**Comparison of Activity between sessions with and without helper**: 
```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}

expdata$value.Experimental <- factor(expdata$value.Experimental)
expdata$value.Activity <- factor(expdata$value.Activity)
exptab <- xtabs(~value.Activity+value.Experimental,data = expdata)
exptab
chisq.test(exptab)
```

Interestingly, there _is_ a certain difference in what the teacher did (basically, there was more time in REPairs in the sessions without helper (but that can be very well linked to the amount of help needed by different cohorts of students -- or that MONitoring only lasts until somebody needs help, which is more common the more groups a teacher has to manage)






#### Social dimension

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# Overall behavioral analyses
# SOCIAL
behdata <- loaddata[(!is.na(loaddata$value.Social)),]
behdata$value.Social <- factor(behdata$value.Social)
# chi-squared test and counts/residuals table for teacher activity
tabSoc <- table(behdata$CoarseLoad,behdata$value.Social)
chisq.test(tabSoc)
tabSoc
chisq.test(tabSoc)$residuals

# Plotting against the FineLoad confirms the trends of CoarseLoad (even with its tendency towards the mean)
g1 <- ggplot(loaddata[!is.na(loaddata$value.Social),],aes(value.Social,FineLoad)) + geom_boxplot(aes(fill=value.Social)) + geom_jitter(aes(col=session))
print(g1)
# Another way of seeing this, in the PCA diagram
soc.res.pca = PCA(loaddata[, c(3:6,10:13,8)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=9)
plot.PCA(soc.res.pca, axes=c(1, 2), choix="ind", habillage=9, invisible="ind")
plot.PCA(soc.res.pca, axes=c(3, 4), choix="ind", habillage=9, invisible="ind")

# Comparison against the HMM states of load -- The states are different for each session, almost!
# hmmSocTab <- xtabs(~value.Social+MMstate4, data=behdata)
# chisq.test(hmmSocTab)
# hmmSocTab
# chisq.test(hmmSocTab)$residuals
hmmSocTab <- xtabs(~value.Social+MMstate8, data=behdata)
chisq.test(hmmSocTab)
hmmSocTab
chisq.test(hmmSocTab)$residuals

```

Looking at the overall data, we find that **Social plane** seems related to the overall load scores, in a similar way to study 1: CLSsroom level tends to be higher load, and GRP is lower load (there are not enough IND instances to say for sure).

However, looking into the PCA load dimensions, we see clearly the separation among the different social planes: CLS tends to be high cognitive load, and somewhat higher physical load too (with respect to GRP); also, CLS tends to be more fixation-heavy with less attention, while GRP tends to be more saccade speed heavy and with more attention.

Looking at the HMM (8-state) model, we find similar trends: CLS centers around the high-cognitive, low physical load states (HiCognitiveLoadState, MidLowPhysHiCogLoadState, MidLoadState, MidHiCogLowPhysLoadState), while the GRP plane is more in the low-cognitive load -- including both higher and lower physical load (MidHiPhysicalLowCogLoadState, MidLowPhysCogLoadState, LowLoadState)

**Comparison of Social between sessions with and without helper**: 
```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}

expdata$value.Experimental <- factor(expdata$value.Experimental)
expdata$value.Social <- factor(expdata$value.Social)
exptab <- xtabs(~value.Social+value.Experimental,data = expdata)
exptab
chisq.test(exptab)
chisq.test(exptab)$residuals
```

Interestingly, there _is_ a certain difference in who the teacher was interacting with (there was more CLS in the sessions with a helper, probably because the teaccher took more time to solve problems and questions with groups in the session without a helper). This may also help explain why the overall load indicators are bad at catching the helper/no helper conditions: when teacher has help, he spends less time solving group questions (which is lower instantaneous cognitive load), and he has more time to address the whole classroom (which is related to higher cognitive load)!

**So, freeing up resources may lead paradoxically to higher cognitive load (but not all cognitive load is bad!)**


#### Gaze focus dimension

Not analyzed in this study

### E: Session-level analysis and comparison


Since we had no subjective ratings (for the session or for individual episodes) for cognitive load, all we can do is compare the quantitative, sensor-based load values for each session, to get an idea of which session could have been more or less "loading"

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# Plotting the FineLoad of each session
g1 <- ggplot(loaddata,aes(session,FineLoad)) + geom_boxplot(aes(fill=session))
print(g1)
g1 <- ggplot(loaddata,aes(FineLoad)) + geom_density(aes(col=session))
print(g1)

# Plotting against the PCA and HMM dimensions
# g1 <- ggplot(loaddata,aes(PupilLoadDim)) + geom_density(aes(col=session))
# print(g1)
# g1 <- ggplot(loaddata,aes(EyeMoveFixLoadDim)) + geom_density(aes(col=session))
# print(g1)
loaddata$session <- factor(loaddata$session)
sess.res.pca = PCA(loaddata[, c(3:6,10:13,2)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=9)
plot.PCA(sess.res.pca, axes=c(1, 2), choix="ind", habillage=9, invisible="ind")
plot.PCA(sess.res.pca, axes=c(3, 4), choix="ind", habillage=9, invisible="ind")


# Comparison against the HMM states of load
hmmSessTab <- xtabs(~session+MMstate8, data=loaddata)
chisq.test(hmmSessTab)
hmmSessTab
chisq.test(hmmSessTab)$residuals

# TODO: We can also calculate the new values of load taking as reference the median threshold of the first session

```

We see that, despite differences being small (as all sessions were very similar in terms of what was done), session 4 seemed to have more abundance of high-load episodes.

The PCA dimensions help us see that differences are quite small, especially in terms of physical load (sessions 2 and 4 were more physical load) and cognitive load (session 2 was less cognitive load); differences in the fixation/saccade dimension are also small, but there is quite a noticeable difference in the attention dimension (session 4 was more EEG/attention-related load).

The analysis from the point of view of the HMM states is also interesting, as there are some differences (without reaching a level of session-specific states): session 1 was richer in MidLoadState episodes, while session 1; session 2 had more HiPhysicalFixLoadState episodes; session 3 was more "average" in terms of states, while session 4 had more HiCognitiveLoadState and MidLowPhysCogLoadState.




```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# We come to the root folder, for the next study
setwd(rootdir)
```
