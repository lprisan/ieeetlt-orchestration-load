---
title: "Study 3 Alternative Analysis"
author: "Luis P."
date: "January 15, 2016"
output: html_document
---

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=3, fig.width=8}
library(ggplot2)
# We load the useful scripts and packages needed throughout the report
source("./lib/rollingWindows.R")
source("./lib/loadIndex.R")
source("./lib/extremeLoadExtraction.R")
source("./lib/aggregateEpisodeData.R")
source("./lib/multiplot.R")
source("./lib/outliers.R")
source('./lib/codeAnalyses.R')


rootdir <- getwd()
setwd(paste(rootdir,"/data/study3",sep=""))

# We do the preprocessing, which will generate a Rda file with the 10s
# window data, and will return the name of the file

sessions <-  c("ISL2014BASELINE-Session1-eyetracking","ISL2014BASELINE-Session2-eyetracking","ISL2015NOVEL-Session3-eyetracking","ISL2015NOVEL-Session4-eyetracking")

cleandatafile <- "study3ProcessedData.Rda"

totaldata <- get(load(cleandatafile))

# We crop outliers in the saccade speed. They tend to throw off the HMM and PCA calculations
#countOutliers(totaldata$value.Sac,coef = 5, method="iqr") # 5xinter-quartile range
totaldata$value.Sac <- replaceOutliers(totaldata$value.Sac,valueNA = F,coef = 5, method="iqr")

# We remove the NAs generated by the outlier removal, for all the subsequent calculations
totaldata <- totaldata[!is.na(totaldata$value.Sac),]

loaddata <- calculateCoarseFineLoadIndex(totaldata,3:6,normalize=T) # We ensure that the values are normalized for those of the first window in which little load is assumed (just putting the eyetracker on)
#str(loaddata)

# We assume that the teacher load in the novel technology sessions is higher than in the novice sessions
loaddata$TeacherLoad <- ifelse(loaddata$session==sessions[3] | loaddata$session==sessions[4],1,0)
# table(loaddata$TeacherLoad,loaddata$Activity)
# table(loaddata$TeacherLoad,loaddata$Social)
# table(loaddata$TeacherLoad,loaddata$Focus)

names(loaddata)
```

# Exploratory analysis of the physiological signals

... always taking into account the normalized values, not the raw ones!

## Correlations

```{r, cache=FALSE, echo=FALSE, message=FALSE, warning=FALSE, fig.height=5, fig.width=5}
library(corrplot)
M <- cor(loaddata[, c(19,22,25,28)],use="complete.obs")
corrplot.mixed(M,main="Correlations, normalized values")

datausual <- loaddata[loaddata$TeacherLoad==0,]
datanovel <- loaddata[loaddata$TeacherLoad==1,]

#... and for the two techs separately
M <- cor(datausual[, c(19,22,25,28)],use="complete.obs")
corrplot.mixed(M,main="Correlations, Usual tech, normalized values")

M <- cor(datanovel[, c(19,22,25,28)],use="complete.obs")
corrplot.mixed(M,main="Correlations, Novel tech, normalized values")

```

We see correlations are far from perfect, which is to be expected, given that different metrics can catch different parts of the multitask activity.

However, it is interesting that the SAME TEACHER, depending on the kind of situation, has also different correlations among the load metrics, indicating that these metrics not only vary from person to person, but also in different kinds of situations. 

PCA dimensions, models, etc. should probably be calculated separately.


## PCA

### Overall PCA

```{r, cache=FALSE, echo=FALSE, message=FALSE, warning=FALSE, fig.height=5, fig.width=5}
library(FactoMineR)

#Overall for the usual sessions
res.pca.norm = PCA(loaddata[, c(19,22,25,28)], scale.unit=TRUE, ncp=5, graph=F)
plot.PCA(res.pca.norm, axes=c(1, 2), choix="var", title="PCA, Normalized data, ALL DATA, dims 1/2")
loaddata$Dim1Norm = res.pca.norm$ind$coord[,1]
loaddata$Dim2Norm = res.pca.norm$ind$coord[,2]

aggregate(loaddata[,c("Dim1Norm","Dim2Norm","CoarseLoad")],list(loaddata$CoarseLoad),FUN=mean)


datausual <- loaddata[loaddata$TeacherLoad==0,]
datanovel <- loaddata[loaddata$TeacherLoad==1,]


```

We see that the 1st PCA dimension is somewhat opposite to the CoarseLoad, while Dim2 goes with the Coarse load more linearly

### Usual technology

We do NOT do different PCAs per condition! Just plot them to check they are somewhat similar

```{r, cache=FALSE, echo=FALSE, message=FALSE, warning=FALSE, fig.height=5, fig.width=5, eval=T}
# library(FactoMineR)
# 
# #Overall for the usual sessions
res.pca.norm = PCA(datausual[, c(19,22,25,28)], scale.unit=TRUE, ncp=5, graph=F)
plot.PCA(res.pca.norm, axes=c(1, 2), choix="var", title="PCA, Normalized data, Usual tech, dims 1/2")
# datausual$Dim1Norm = res.pca.norm$ind$coord[,1]
# datausual$Dim2Norm = res.pca.norm$ind$coord[,2]
# 
# # How does this PCA dimension relate to the Load Index?
# 
# library(ggplot2)
# #ggplot(data, aes(x=Dim1Norm, col=factor(CoarseLoad)))+geom_density()
# #ggplot(loaddata, aes(x=Dim1Norm, y=FineLoad))+geom_point()+geom_smooth()
# #ggplot(loaddata, aes(x=Dim2Norm, y=FineLoad))+geom_point()+geom_smooth()
# 
# aggregate(datausual[,c("Dim1Norm","Dim2Norm","CoarseLoad")],list(datausual$CoarseLoad),FUN=mean)
# 
# # We see that actually the first dimension of PCA is rather different to the Coarse/fine load overall metric, and actually is the second dimension of PCA which correlates better with the Coarse load!

```


### Novel technology

We do NOT do different PCAs per condition! Only plot FYI

```{r, cache=FALSE, echo=FALSE, message=FALSE, warning=FALSE, fig.height=5, fig.width=5, eval=T}
# library(FactoMineR)
# 
# #Overall for the four sessions
res.pca.norm = PCA(datanovel[, c(19,22,25,28)], scale.unit=TRUE, ncp=5, graph=F)
plot.PCA(res.pca.norm, axes=c(1, 2), choix="var", title="PCA, Normalized data, Novel tech, dims 1/2")
# datanovel$Dim1Norm = res.pca.norm$ind$coord[,1]
# datanovel$Dim2Norm = res.pca.norm$ind$coord[,2]
# 
# # How does this PCA dimension relate to the Load Index?
# 
# 
# library(ggplot2)
# #ggplot(data, aes(x=Dim1Norm, col=factor(CoarseLoad)))+geom_density()
# #ggplot(loaddata, aes(x=Dim1Norm, y=FineLoad))+geom_point()+geom_smooth()
# #ggplot(loaddata, aes(x=Dim2Norm, y=FineLoad))+geom_point()+geom_smooth()
# 
# aggregate(datanovel[,c("Dim1Norm","Dim2Norm","CoarseLoad")],list(datanovel$CoarseLoad),FUN=mean)
# 
# #In this case the main PCA dimension and the Load index are not that different, and the second dimension seems to go in a somewhat opposite direction of the Coarse Load index.


```


## t-SNE

Alternative to PCA for dimensionality reduction, to better see clusters in the data...

```{r, cache=FALSE, echo=FALSE, message=FALSE, warning=FALSE, fig.height=5, fig.width=5, eval=F}
library(tsne)
tSNE.norm <- tsne(loaddata[, c(19,22,25,28)])

loaddata$tsne1 <- tSNE.norm[,1]
loaddata$tsne2 <- tSNE.norm[,2]
ggplot(loaddata, aes(x=tsne1,y=tsne2, col=factor(CoarseLoad)))+geom_point()
ggplot(loaddata, aes(x=tsne1,y=tsne2, col=factor(Activity)))+geom_point()
ggplot(loaddata, aes(x=tsne1,y=tsne2, col=factor(Social)))+geom_point()
ggplot(loaddata, aes(x=tsne1,y=tsne2, col=factor(Focus)))+geom_point()
ggplot(loaddata, aes(x=tsne1,y=tsne2, col=factor(TeacherLoad)))+geom_point()
ggplot(loaddata, aes(x=tsne1,y=tsne2, col=factor(session)))+geom_point()

#ggplot(loaddata, aes(x=tsne1,y=tsne2, col=Dim1Norm))+geom_point()+ scale_colour_gradient2(low="#22FF00", mid="white", high="#FF0000", midpoint=median(loaddata$Dim1Norm)) + theme(panel.grid=element_blank(), panel.background=element_rect(fill="black"))


```


# How each signal behaves with respect to the behavioral codes

## Usual tech

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}
library(gplots)

behdata <- datausual[!is.na(datausual$Activity) & !is.na(datausual$Social) & !is.na(datausual$Focus),]
#table(behdata$Social)
#table(behdata$Activity)
#table(behdata$Focus)
behdata <- behdata[behdata$Activity!="OFF",]
behdata <- behdata[behdata$Activity!="TEC",]
behdata <- behdata[behdata$Activity!="DISC",]
behdata$Activity <- factor(behdata$Activity)
behdata <- behdata[behdata$Social!="GRP",]
behdata$Social <- factor(behdata$Social)
behdata <- behdata[behdata$Focus!="BAK",]
behdata <- behdata[behdata$Focus!="CHR",]
behdata <- behdata[behdata$Focus!="PRJ",]
behdata <- behdata[behdata$Focus!="RES",]
behdata <- behdata[behdata$Focus!="TAB",]
behdata <- behdata[behdata$Focus!="TNG",]
behdata <- behdata[behdata$Focus!="TPAP",]
behdata$Focus <- factor(behdata$Focus)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}
ggplot(behdata, aes(x=value.Mean.norm))+geom_density()

plotmeans(behdata$value.Mean.norm~behdata$Activity)
plotmeans(behdata$value.Mean.norm~behdata$Social)
plotmeans(behdata$value.Mean.norm~behdata$Focus)

```

The mean pupil diameter could be affected by the high luminosity of the laptop/computer (but the paper is lower, and does not have necessarily higher luminosity). A linear model tells us that the trends in activities are similar after removing the effect of the focus, although the effect of social level (IND being lower) is not significant then.


```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5, eval=TRUE}
lm1 <- lm(value.Mean.norm ~ Activity + Social + Focus, data = behdata)
summary(lm1)
anova(lm1)
```


```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}
ggplot(behdata, aes(x=value.SD.norm))+geom_density()

plotmeans(behdata$value.SD.norm~behdata$Activity)
plotmeans(behdata$value.SD.norm~behdata$Social)
plotmeans(behdata$value.SD.norm~behdata$Focus)

```

AGain, the SD pupil diameter could be affected by the high luminosity of the laptop but the linear model tells us that the trends are similar even taking out the influence of other dimensions.

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5, eval=TRUE}
lm1 <- lm(value.SD.norm ~ Activity + Social + Focus, data = behdata)
summary(lm1)
anova(lm1)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}
ggplot(behdata, aes(x=value.Sac.norm))+geom_density()

plotmeans(behdata$value.Sac.norm~behdata$Activity)
plotmeans(behdata$value.Sac.norm~behdata$Social)
plotmeans(behdata$value.Sac.norm~behdata$Focus)

```

The Saccade Speed seems to have a peculiar bimodal distribution (probably due to the sampling done of the session). The saccade speed differences in the social level (CLS is higher) could be explained physically. The linear model tells us that even taking that factor out, the other trends are still similar to the averages above (although social and focus stop being significant factors in the model)

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5, eval=TRUE}
lm1 <- lm(value.Sac.norm ~ Activity + Social + Focus, data = behdata)
summary(lm1)
anova(lm1)
```


```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}
ggplot(behdata, aes(x=value.Fix.norm))+geom_density()

plotmeans(behdata$value.Fix.norm~behdata$Activity)
plotmeans(behdata$value.Fix.norm~behdata$Social)
plotmeans(behdata$value.Fix.norm~behdata$Focus)

```

(Here I cannot see any specific trend that can be explained in purely physical terms)

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5, eval=TRUE}
lm1 <- glm(value.Fix.norm ~ Activity + Social + Focus, family="poisson", data = behdata)
summary(lm1)
anova(lm1, test="Chisq")
```

## Novel technology

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}
library(gplots)

behdata <- datanovel[!is.na(datanovel$Activity) & !is.na(datanovel$Social) & !is.na(datanovel$Focus),]
#table(behdata$Social)
#table(behdata$Activity)
#table(behdata$Focus)
behdata <- behdata[behdata$Activity!="OFF",]
behdata <- behdata[behdata$Activity!="TEC",]
behdata <- behdata[behdata$Activity!="DISC",]
behdata$Activity <- factor(behdata$Activity)
behdata <- behdata[behdata$Focus!="LAP",]
behdata <- behdata[behdata$Focus!="CHR",]
behdata <- behdata[behdata$Focus!="RES",]
behdata <- behdata[behdata$Focus!="TNG",]
behdata <- behdata[behdata$Focus!="TPAP",]
behdata$Focus <- factor(behdata$Focus)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}
ggplot(behdata, aes(x=value.Mean.norm))+geom_density()

plotmeans(behdata$value.Mean.norm~behdata$Activity)
plotmeans(behdata$value.Mean.norm~behdata$Social)
plotmeans(behdata$value.Mean.norm~behdata$Focus)

```

The mean pupil diameter could be affected by the high luminosity of the tabletop or the projector, but a linear model tells us that the effects of all three dimensions are relevant, even removing the effects of the others


```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5, eval=TRUE}

lm1 <- lm(value.Mean.norm ~ Activity + Social + Focus, data = behdata)
summary(lm1)
anova(lm1)
```


```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}
ggplot(behdata, aes(x=value.SD.norm))+geom_density()

plotmeans(behdata$value.SD.norm~behdata$Activity)
plotmeans(behdata$value.SD.norm~behdata$Social)
plotmeans(behdata$value.SD.norm~behdata$Focus)

```

AGain, the SD pupil diameter could be affected by the high luminosity of the laptop but the linear model tells us that the trends are similar (activity is not so important, social and focus are) even taking out the influence of other dimensions

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5, eval=TRUE}
lm1 <- lm(value.SD.norm ~ Activity + Social + Focus, data = behdata)
summary(lm1)
anova(lm1)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}
ggplot(behdata, aes(x=value.Sac.norm))+geom_density()

plotmeans(behdata$value.Sac.norm~behdata$Activity)
plotmeans(behdata$value.Sac.norm~behdata$Social)
plotmeans(behdata$value.Sac.norm~behdata$Focus)

```

The Saccade Speed seems to have a peculiar bimodal distribution (probably due to the sampling done of the session), and the differences in this metric do not seem relevant in any dimension (as confirmed too by the linear model below)

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5, eval=TRUE}
lm1 <- lm(value.Sac.norm ~ Activity + Social + Focus, data = behdata)
summary(lm1)
anova(lm1)
```


```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}
ggplot(behdata, aes(x=value.Fix.norm))+geom_density()

plotmeans(behdata$value.Fix.norm~behdata$Activity)
plotmeans(behdata$value.Fix.norm~behdata$Social)
plotmeans(behdata$value.Fix.norm~behdata$Focus)

```

(Here I cannot see any specific trend that can be explained in purely physical terms)



```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5, eval=TRUE}
lm1 <- glm(value.Fix.norm ~ Activity + Social + Focus, family="poisson", data = behdata)
summary(lm1)
anova(lm1, test="Chisq")
```


# Descriptive behavioral patterns

We coded the parts of the session where we are most confident that load is high (Coarse Load Index=4) or low (Coarse Load Index=4). What are the observed trends in terms of teacher Activity, Social plane and Focus of the gaze?

## Usual technology


### In terms of Load Index


We train a logistic regression model that tries to predict whether a coded episode was of the high or low load kind, using Activity, Social plane and Focus of the gaze as predictor variables, and see which ones are most predictive:

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}

library(aod)
library(ggplot2)

behdata <- datausual[!is.na(datausual$Activity) & !is.na(datausual$Social) & !is.na(datausual$Focus),]
behdata <- behdata[behdata$Activity!="OFF",]
behdata <- behdata[behdata$Activity!="TEC",]
behdata <- behdata[behdata$Activity!="DISC",]
behdata$Activity <- factor(behdata$Activity)
behdata <- behdata[behdata$Social!="GRP",]
behdata$Social <- factor(behdata$Social)
behdata <- behdata[behdata$Focus!="BAK",]
behdata <- behdata[behdata$Focus!="CHR",]
behdata <- behdata[behdata$Focus!="PRJ",]
behdata <- behdata[behdata$Focus!="RES",]
behdata <- behdata[behdata$Focus!="TAB",]
behdata <- behdata[behdata$Focus!="TNG",]
behdata <- behdata[behdata$Focus!="TPAP",]
behdata$Focus <- factor(behdata$Focus)

#table(behdata$CoarseLoad)

behdata$CoarseType <- ifelse(behdata$CoarseLoad>2,1,0)
behdata$CoarseType <- ifelse(behdata$CoarseLoad==2,NA,behdata$CoarseType)
table(behdata$CoarseType,behdata$Activity)
table(behdata$CoarseType,behdata$Social)
table(behdata$CoarseType,behdata$Focus)


logit1 <- glm(CoarseType ~ Activity + Social + Focus, data = behdata, family = "binomial")
summary(logit1)
exp(coef(logit1)) # To see odds ratio change for each variable
anova(logit1, test="Chisq")
library(pscl)
pR2(logit1)# pseudo R^2, to see the model fit


```

We see that in this case the model is very predictive (pseudo-Rsquared of 0.75), although there are not enough instances of all cases to trust the model too much.

The three dimensions seem significant to determine the kind of load episode: (EXP, QUE, CLS, FAC being higher load), and LAP (MON, PAP and TCOMP) being lower load.


### In terms of PCA-extracted Index

The distribution of coded values goes continuouosly along the dimension, so we do a linear model in this case, that tries to predict the PCA dimension, using Activity, Social plane and Focus of the gaze as predictor variables, and see which ones are most predictive:

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}


#ggplot(datausual,aes(x=Dim1Norm))+geom_density()
ggplot(behdata,aes(x=Dim1Norm))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model


lm1 <- lm(Dim1Norm ~ Activity + Social + Focus, data = behdata)
summary(lm1)
anova(lm1)

```

We see that, in this case, all three of the dimensions are significant at the 0.05 level, and the adjusted Rsquared=0.30. The most noticeable patterns were that EXP, CLS are lower load, while TDT, IND, LAP, PAP were higher load.



## Novel technology


### In terms of Load Index


We train a logistic regression model that tries to predict whether a coded episode was of the high or low load kind, using Activity, Social plane and Focus of the gaze as predictor variables, and see which ones are most predictive:

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}

library(aod)
library(ggplot2)

behdata <- datanovel[!is.na(datanovel$Activity) & !is.na(datanovel$Social) & !is.na(datanovel$Focus),]
#table(behdata$Social)
#table(behdata$Activity)
#table(behdata$Focus)
behdata <- behdata[behdata$Activity!="OFF",]
behdata <- behdata[behdata$Activity!="TEC",]
behdata <- behdata[behdata$Activity!="DISC",]
behdata$Activity <- factor(behdata$Activity)
behdata <- behdata[behdata$Focus!="LAP",]
behdata <- behdata[behdata$Focus!="CHR",]
behdata <- behdata[behdata$Focus!="RES",]
behdata <- behdata[behdata$Focus!="TNG",]
behdata <- behdata[behdata$Focus!="TPAP",]
behdata$Focus <- factor(behdata$Focus)

#table(behdata$CoarseLoad)

behdata$CoarseType <- ifelse(behdata$CoarseLoad>2,1,0)
behdata$CoarseType <- ifelse(behdata$CoarseLoad==2,NA,behdata$CoarseType)
# table(behdata$CoarseType)
table(behdata$CoarseType,behdata$Activity)
table(behdata$CoarseType,behdata$Social)
table(behdata$CoarseType,behdata$Focus)


logit1 <- glm(CoarseType ~ Activity + Social + Focus, data = behdata, family = "binomial")
summary(logit1)
exp(coef(logit1)) # To see odds ratio change for each variable
anova(logit1, test="Chisq")
library(pscl)
pR2(logit1)# pseudo R^2, to see the model fit


```

We see that in this case the model is more predictive than for the usual tech lessons (pseudo Rsquared=0.46), maybe indicating that trends in the data are much more clear (again, maybe because overall load was higher, as expected). It looks like EXP and REP, CLS, FAC tends to be higher load and GRP, PRJ, TAB lower load.




### In terms of PCA-extracted Index

The distribution of coded values goes continuouosly along the dimension, so we do a linear model in this case, that tries to predict the PCA dimension, using Activity, Social plane and Focus of the gaze as predictor variables, and see which ones are most predictive:

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}


ggplot(behdata,aes(x=Dim1Norm))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model

lm1 <- lm(Dim1Norm ~ Activity + Social + Focus, data = behdata)
summary(lm1)
anova(lm1)

```

Interestingly, in this case the linear model based on the orchestration dimensions does not give a very predictive model (adjusted Rsquared<0.03), and none of the dimensions is significant. However, the bimodal distribution profile of the data 


```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}

ggplot(behdata,aes(x=Dim1Norm, col=factor(session)))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model

behdata3 <- behdata[behdata$session==sessions[3],]
behdata4 <- behdata[behdata$session==sessions[4],]

lm3 <- lm(Dim1Norm ~ Activity + Social + Focus, data = behdata3)
summary(lm3)
anova(lm3)

lm4 <- lm(Dim1Norm ~ Activity + Social + Focus, data = behdata4)
summary(lm4)
anova(lm4)

```

We see that the PCA load index of the two novel technology sessions are much better explained by separate per-session models:

* In the **first novel** technology session, Activity and Social are significant factors, with CLS, EXP being lower load and MON, QUE, TDT, GRP, IND being higher load.
* In the **second novel** technology session, Social (and Focus) are significant factors, with CLS, EXP (,TAB) being lower load and GRP, IND being higher load.


# Using the "experimental condition" (teacher expertise with the technology) to predict the different load indices... is there any difference?

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}

# behdata <- datausual[!is.na(datausual$Activity) & !is.na(datausual$Social) & !is.na(datausual$Focus),]
# behdata <- behdata[behdata$Activity!="OFF",]
# behdata <- behdata[behdata$Activity!="TEC",]
# behdata <- behdata[behdata$Activity!="DISC",]
# behdata$Activity <- factor(behdata$Activity)
# behdata <- behdata[behdata$Social!="GRP",]
# behdata$Social <- factor(behdata$Social)
# behdata <- behdata[behdata$Focus!="BAK",]
# behdata <- behdata[behdata$Focus!="CHR",]
# behdata <- behdata[behdata$Focus!="PRJ",]
# behdata <- behdata[behdata$Focus!="RES",]
# behdata <- behdata[behdata$Focus!="TAB",]
# behdata <- behdata[behdata$Focus!="TNG",]
# behdata <- behdata[behdata$Focus!="TPAP",]
# behdata$Focus <- factor(behdata$Focus)
# 
# 
# #table(behdata$CoarseLoad)
# 
# data <- behdata
# 
# 
# 
# behdata <- datanovel[!is.na(datanovel$Activity) & !is.na(datanovel$Social) & !is.na(datanovel$Focus),]
# behdata <- behdata[behdata$Activity!="OFF",]
# behdata <- behdata[behdata$Activity!="TEC",]
# behdata <- behdata[behdata$Activity!="DISC",]
# behdata$Activity <- factor(behdata$Activity)
# behdata <- behdata[behdata$Focus!="LAP",]
# behdata <- behdata[behdata$Focus!="CHR",]
# behdata <- behdata[behdata$Focus!="RES",]
# behdata <- behdata[behdata$Focus!="TNG",]
# behdata <- behdata[behdata$Focus!="TPAP",]
# behdata$Focus <- factor(behdata$Focus)
# 
# data <- rbind(data,behdata)
data <- loaddata[!is.na(loaddata$Activity) & !is.na(loaddata$Social) & !is.na(loaddata$Focus),]
data$CoarseType <- ifelse(data$CoarseLoad>2,1,0)
data$CoarseType <- ifelse(data$CoarseLoad==2,NA,data$CoarseType)

```

I see two ways of doing it: 1) logistic regression to predict teacher using the load index as parameter (is it significant and positively correlated?);
2) linear model using the teacher as parameter, substracting the others and doing a t test!

<!--
## Method 1: Logistic regression (TODO check with Lukasz)

### Load Index

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}

logit1 <- glm(TeacherLoad ~ Activity + Social + Focus + FineLoad, data = data, family = "binomial")
summary(logit1)
exp(coef(logit1)) # To see odds ratio change for each variable
anova(logit1, test="Chisq")
library(pscl)
pR2(logit1)# pseudo R^2, to see the model fit

logit1 <- glm(TeacherLoad ~ Activity + Social + Focus + CoarseType, data = data, family = "binomial")
summary(logit1)
exp(coef(logit1)) # To see odds ratio change for each variable
anova(logit1, test="Chisq")
library(pscl)
pR2(logit1)# pseudo R^2, to see the model fit


```

With this method, it looks like the FineLoad is a very bad predictor for the type of session (the higher it gets, the lower the chance of a high-load session)! Coarse Type, similarly, gives opposite results to those expected, in a significant way.


### PCA Load Index

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}

logit1 <- glm(TeacherLoad ~ Activity + Social + Focus + Dim1Norm, data = data, family = "binomial")
summary(logit1)
exp(coef(logit1)) # To see odds ratio change for each variable
anova(logit1, test="Chisq")
library(pscl)
pR2(logit1)# pseudo R^2, to see the model fit

# logit2 <- glm(TeacherLoad ~ Activity + Social + Focus + Dim2Norm, data = data, family = "binomial")
# summary(logit2)
# exp(coef(logit2)) # To see odds ratio change for each variable
# anova(logit2, test="Chisq")
# library(pscl)
# pR2(logit2)# pseudo R^2, to see the model fit

```

With this method, it looks like the Dim1 is a good predictor... in the right direction!

### Try individual metrics too??

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}

logit1 <- glm(TeacherLoad ~ Activity + Social + Focus + value.Mean.norm, data = data, family = "binomial")
summary(logit1)
exp(coef(logit1)) # To see odds ratio change for each variable
anova(logit1, test="Chisq")
library(pscl)
pR2(logit1)# pseudo R^2, to see the model fit

```

With this method, we see that the pupil mean alone, however, is not a very significant predictor (although it goes in the right direction)
-->

## Method 2: Linear model (build the model WITHOUT the experimental condition)


### Load Index

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}
library(dummies)



# lm1 <- lm(FineLoad ~ Activity + Social + Focus + TeacherLoad, data = data)
# summary(lm1)
# anova(lm1)
# 
# data2 <- data
# data2 <- cbind(data2,data.frame(dummy("Activity",data2)))
# data2 <- cbind(data2,data.frame(dummy("Social",data2)))
# data2 <- cbind(data2,data.frame(dummy("Focus",data2)))
# 
predmodel <- function(model,data,cols){
    preds <- numeric()
    for(row in 1:nrow(data)){
        sum <- model$coefficients["(Intercept)"]
        for(i in cols){
           coef <- model$coefficients[names(data[row,])[i]]
           if(!is.na(coef)){
             sum <- sum+(coef*data[row,i])   
           }
        }
        preds[row] <- sum        
    }
    
    preds
}
# 
# data2$resid <- data2$FineLoad - predmodel(lm1,data2,37:54)
# #ggplot(data2, aes(x=resid,col=factor(TeacherLoad)))+geom_density()
# 
# t.test(data2[data2$TeacherLoad==0,"resid"],data2[data2$TeacherLoad==1,"resid"])
# 
# 
# lm1 <- lm(CoarseLoad ~ Activity + Social + Focus + TeacherLoad, data = data)
# summary(lm1)
# anova(lm1)
# 
# data2 <- data
# data2 <- cbind(data2,data.frame(dummy("Activity",data2)))
# data2 <- cbind(data2,data.frame(dummy("Social",data2)))
# data2 <- cbind(data2,data.frame(dummy("Focus",data2)))
# 
# data2$resid <- data2$CoarseLoad - predmodel(lm1,data2,37:54)
# #ggplot(data2, aes(x=resid,col=factor(TeacherLoad)))+geom_density()
# 
# t.test(data2[data2$TeacherLoad==0,"resid"],data2[data2$TeacherLoad==1,"resid"])

#TODO: This alternative method is the good one!
# Alternative: building the model without Experimental condition -- in this case the residuals are not significant!
lm1 <- lm(FineLoad ~ Activity + Social + Focus, data = data)
summary(lm1)
anova(lm1)
data2 <- data
data2 <- cbind(data2,data.frame(dummy("Activity",data2)))
data2 <- cbind(data2,data.frame(dummy("Social",data2)))
data2 <- cbind(data2,data.frame(dummy("Focus",data2)))
data2$resid <- data2$FineLoad - predmodel(lm1,data2,37:54)
t.test(data2[data2$TeacherLoad==0,"resid"],data2[data2$TeacherLoad==1,"resid"])
ggplot(data2, aes(x=resid),col=factor(TeacherLoad))+geom_density()

lm1 <- lm(CoarseLoad ~ Activity + Social + Focus, data = data)
summary(lm1)
anova(lm1)
data2 <- data
data2 <- cbind(data2,data.frame(dummy("Activity",data2)))
data2 <- cbind(data2,data.frame(dummy("Social",data2)))
data2 <- cbind(data2,data.frame(dummy("Focus",data2)))
data2$resid <- data2$CoarseLoad - predmodel(lm1,data2,37:54)
t.test(data2[data2$TeacherLoad==0,"resid"],data2[data2$TeacherLoad==1,"resid"])
ggplot(data2, aes(x=resid),col=factor(TeacherLoad))+geom_density()


```

With this method, it looks like TeacherLoad is an important contribution to the model... the t-test shows us that the difference in FineLoad (and even in CoarseLoad) is not significant

### PCA Load Index

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}

# lm1 <- lm(Dim1Norm ~ Activity + Social + Focus + TeacherLoad, data = data)
# summary(lm1)
# anova(lm1)
# 
# data2 <- data
# data2 <- cbind(data2,data.frame(dummy("Activity",data2)))
# data2 <- cbind(data2,data.frame(dummy("Social",data2)))
# data2 <- cbind(data2,data.frame(dummy("Focus",data2)))
# 
# data2$resid <- data2$Dim1Norm - predmodel(lm1,data2,37:54)
# # ggplot(data2, aes(x=resid,col=factor(TeacherLoad)))+geom_density()
# t.test(data2[data2$TeacherLoad==0,"resid"],data2[data2$TeacherLoad==1,"resid"])

# Alternative: building the model without Experimental condition -- in this case the residuals are significantly different as well!
lm1 <- lm(Dim1Norm ~ Activity + Social + Focus, data = data)
summary(lm1)
anova(lm1)
data2 <- data
data2 <- cbind(data2,data.frame(dummy("Activity",data2)))
data2 <- cbind(data2,data.frame(dummy("Social",data2)))
data2 <- cbind(data2,data.frame(dummy("Focus",data2)))
data2$resid <- data2$Dim1Norm - predmodel(lm1,data2,37:54)
t.test(data2[data2$TeacherLoad==0,"resid"],data2[data2$TeacherLoad==1,"resid"])
ggplot(data2, aes(x=resid,col=factor(TeacherLoad)))+geom_density()


```

With this method, it looks like TeacherLoad is an important contribution to the model... the t-test shows us that the difference in Dim1 PCA once we remove the influence of Activity, Social and Focus, IS significant between the cases with usual and novel technology.

### Try individual metrics too??

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}

# lm1 <- lm(value.Mean.norm ~ Activity + Social + Focus + TeacherLoad, data = data)
# summary(lm1)
# anova(lm1)
# 
# data2 <- data
# data2 <- cbind(data2,data.frame(dummy("Activity",data2)))
# data2 <- cbind(data2,data.frame(dummy("Social",data2)))
# data2 <- cbind(data2,data.frame(dummy("Focus",data2)))
# 
# data2$resid <- data2$value.Mean.norm - predmodel(lm1,data2,37:51)
# # ggplot(data2, aes(x=resid,col=factor(TeacherLoad)))+geom_density()
# 
# t.test(data2[data2$TeacherLoad==0,"resid"],data2[data2$TeacherLoad==1,"resid"])

# Alternative: building the model without Experimental condition -- in this case the residuals are not significantly different!
lm1 <- lm(value.Mean.norm ~ Activity + Social + Focus, data = data)
summary(lm1)
anova(lm1)
data2 <- data
data2 <- cbind(data2,data.frame(dummy("Activity",data2)))
data2 <- cbind(data2,data.frame(dummy("Social",data2)))
data2 <- cbind(data2,data.frame(dummy("Focus",data2)))
data2$resid <- data2$value.Mean.norm - predmodel(lm1,data2,37:51)
t.test(data2[data2$TeacherLoad==0,"resid"],data2[data2$TeacherLoad==1,"resid"])
ggplot(data2, aes(x=resid,col=factor(TeacherLoad)))+geom_density()

lm1 <- lm(value.SD.norm ~ Activity + Social + Focus, data = data)
summary(lm1)
anova(lm1)
data2 <- data
data2 <- cbind(data2,data.frame(dummy("Activity",data2)))
data2 <- cbind(data2,data.frame(dummy("Social",data2)))
data2 <- cbind(data2,data.frame(dummy("Focus",data2)))
data2$resid <- data2$value.SD.norm - predmodel(lm1,data2,37:51)
t.test(data2[data2$TeacherLoad==0,"resid"],data2[data2$TeacherLoad==1,"resid"])
ggplot(data2, aes(x=resid))+geom_density()

lm1 <- lm(value.Sac.norm ~ Activity + Social + Focus, data = data)
summary(lm1)
anova(lm1)
data2 <- data
data2 <- cbind(data2,data.frame(dummy("Activity",data2)))
data2 <- cbind(data2,data.frame(dummy("Social",data2)))
data2 <- cbind(data2,data.frame(dummy("Focus",data2)))
data2$resid <- data2$value.Sac.norm - predmodel(lm1,data2,37:51)
t.test(data2[data2$TeacherLoad==0,"resid"],data2[data2$TeacherLoad==1,"resid"])
ggplot(data2, aes(x=resid))+geom_density()

# We would need a different predmodel() for poisson models!
lm1 <- glm(value.Fix.norm ~ Activity + Social + Focus, data = data, family="poisson")
summary(lm1)
anova(lm1, test="Chisq")
data2 <- data
data2 <- cbind(data2,data.frame(dummy("Activity",data2)))
data2 <- cbind(data2,data.frame(dummy("Social",data2)))
data2 <- cbind(data2,data.frame(dummy("Focus",data2)))
predpois <- function(model,data,cols){
    preds <- numeric()
    for(row in 1:nrow(data)){
        sum <- model$coefficients["(Intercept)"]
        for(i in cols){
           coef <- model$coefficients[names(data[row,])[i]]
           if(!is.na(coef)){
             sum <- sum+(coef*data[row,i])   
           }
        }
        preds[row] <- sum        
    }
    
    exp(preds)
}
data2$resid <- data2$value.Fix.norm - predpois(lm1,data2,37:51)
t.test(data2[data2$TeacherLoad==0,"resid"],data2[data2$TeacherLoad==1,"resid"])
ggplot(data2, aes(x=resid))+geom_density()


```

For example, for pupil mean, sd and fixations, there is no significant difference between the usual and novel technology, or there is, but in the wrong direction. Only saccade speed seems significantly different.

# What is the relationship between the eyetracking metrics and the subjective metrics?


## Session-level

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# Compare subjective ratings and comments
setwd(paste(rootdir,"/data/study3",sep=""))

sessionusual <- read.csv("ISL2014BASELINE-sessionratings.csv", sep=";")
sessionnovel <- read.csv("ISL2015NOVEL-sessionratings.csv", sep=",")
rbind.all.columns <- function(x, y) {
 
    x.diff <- setdiff(colnames(x), colnames(y))
    y.diff <- setdiff(colnames(y), colnames(x))
 
    x[, c(as.character(y.diff))] <- NA
 
    y[, c(as.character(x.diff))] <- NA
 
    return(rbind(x, y))
}
sessiondata <- rbind.all.columns(sessionusual,sessionnovel)

print(sessiondata[,c("Session","Subj.Mental.Effort","Subj.Difficulty")])

qplot(sessiondata$Session,sessiondata$TLX.Total,fill=sessiondata$SessionType)+geom_bar(stat = "identity")

ggplot(loaddata,aes(session,FineLoad)) + geom_boxplot(aes(fill=factor(TeacherLoad)))
#ggplot(loaddata,aes(FineLoad)) + geom_density(aes(col=session))

# This is done with the overall PCA... does it make sense?
ggplot(loaddata,aes(session,Dim1Norm)) + geom_boxplot(aes(fill=factor(TeacherLoad)))
#ggplot(loaddata,aes(Dim1Norm)) + geom_density(aes(col=session))

```


## Episode-level (from the stimulated recall)

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}

# names(datausual)
compare <- rbind(datausual[,c("session","TeacherLoad","CoarseLoad","FineLoad","Subjective.Value","Codes","Dim1Norm","Dim2Norm")],datanovel[,c("session","TeacherLoad","CoarseLoad","FineLoad","Subjective.Value","Codes","Dim1Norm","Dim2Norm")])
compare <- compare[complete.cases(compare$Subjective.Value),]
names(compare)
qplot(Subjective.Value, FineLoad, data = compare, geom=c("point","smooth"), method="lm", col=factor(TeacherLoad))
anova(lm(FineLoad~Subjective.Value,data = compare[compare$TeacherLoad==0,]))

cor(compare$Subjective.Value, compare$Dim1Norm) # Correlation 0.27
qplot(Subjective.Value, Dim1Norm, data = compare, geom=c("point","smooth"), method="lm", col=factor(TeacherLoad))
anova(lm(Dim1Norm~Subjective.Value,data = compare))


```

We find that, although in the usual technology sessions the subjective and coarse/fine eyetracking load ratings correlate significantly, but that trend is inverted in the novel technology ones, hence giving a lack of general correlation between both kinds of scores.

Interestingly, the first dimension of PCA DOES correlates more consistently with the subjective load ratings (corr=0.38) for the episodes, in both conditions. And... the correlation IS significant.


### Qualitative analysis


```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.height=5, fig.width=5}

codes <- flattenCodeData(compare,codecol = 6,additionalcol = c(1,2,3,4,5,7,8))

# General DISTRIBUTION OF CODES
#qplot(Code,data=codes,fill=session)+coord_flip()
qplot(Code,data=codes,fill=factor(TeacherLoad))+coord_flip()

codes$splitFine <- ifelse(codes$FineLoad>mean(codes$FineLoad),1,0)
chisq.test(table(codes$Code,codes$splitFine))

codes$splitPCA <- ifelse(codes$Dim1Norm<mean(codes$Dim1Norm),1,0)
chisq.test(table(codes$Code,codes$splitPCA))
chisq.test(table(codes$Code,codes$splitPCA))$residuals

# Vs. PCA dimension
qplot(Code,Dim1Norm,data=codes,geom="boxplot",fill=Code)+geom_jitter()+coord_flip()

```

No clear trends for the qualitative analysis