# Study 1: Feasibility of the Approach (Open Doors Day)

In this case study, we aimed to explore the following research questions: _is it feasible to use a mobile eye-tracker to follow a teacher's cognitive load in a semi-authentic classroom setting? Does such analysis provide interesting insights about classroom usability of a novel technology? Can we detect specific classroom interaction episodes that imply high (or low) cognitive load?_.

The **context** of the data gathering were three sessions of 35-45 minutes long, in a classroom with several tabletop computers, in which classes of around 20 students were playing collaboratively to a tangible tabletop game, to learn about fractions, fraction comparison and equivalence. The teacher was wearing a mobile eye-tracker

## Before starting: Data download and pre-process

First of all, we download the datasets for the three studies, which have been published in Zenodo: 

* [Dataset for Study 1 (Multi-tabletop sessions in the lab, primary school students)](https://zenodo.org/record/16515)

```{r, message=FALSE, warning=FALSE, echo=FALSE}
# We load the useful scripts and packages needed throughout the report
source("./lib/rollingWindows.R")
source("./lib/loadIndex.R")
source("./lib/extremeLoadExtraction.R")
source("./lib/aggregateEpisodeData.R")

rootdir <- getwd()

# If not present already, download dataset study 2 and uncompress it to Study2/
setwd(paste(rootdir,"/data/study1",sep=""))
if(!file.exists("JDC2014-VideoCodingData.zip") || !file.exists("JDC2014-EyetrackingData.zip")){
    download.file("https://zenodo.org/record/16515/files/JDC2014-VideoCodingData.zip", destfile="JDC2014-VideoCodingData.zip", method="curl")
    unzip("JDC2014-VideoCodingData.zip")
    download.file("https://zenodo.org/record/16515/files/JDC2014-EyetrackingData.zip", destfile="JDC2014-EyetrackingData.zip", method="curl")
    unzip("JDC2014-EyetrackingData.zip")
} 

# Now we have the raw data files uncompressed in the data/study1 folder
```

Once we have the raw data from the eye-tracker (plus the video coding data generated by researchers), we pre-process it, mostly by aggregating the four load-related eyetracking metrics (pupil diameter mean, pupil diameter variation, saccade speed and number of fixations >500ms) into 10-second episodes, using a rolling window with 5-second slide between windows (see ```./lib/aggregateEpisodeData.R``` and ```./lib/rollingWindows.R``` files for details).

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
setwd(paste(rootdir,"/data/study1",sep=""))

# We do the preprocessing, which will generate a Rda file with the 10s
# window data, and will return the name of the file

sessions <- c("JDC2014-Session1-eyetracking","JDC2014-Session2-eyetracking","JDC2014-Session3-eyetracking")

cleandatafile <- "study1ProcessedData.Rda"
if(!file.exists(cleandatafile)){
    data <- aggregateEpisodeData(sessions, datadir=paste(rootdir,"/data/study1",sep=""), initendtimes=NULL, SEPARATOR=",") # For this study the raw data is comma-separated!
    data <- data[,c(1:5,12)] # We select only the load-related metrics
    # We load and add the video coding data with the social, activity and main gaze focus dimensions
    videocodes <- data.frame()
    sessionsvid <- c("JDC2014-Session1","JDC2014-Session2","JDC2014-Session3") # For some reason, the filenames for the videocoding are not consistent with the previous session labels
    for(session in sessionsvid){
        sessioncodes <- read.csv(paste(session,"-videocoding.csv",sep = ""), sep=",")
        if(nrow(videocodes)==0) videocodes <- sessioncodes
        else videocodes <- rbind(videocodes,sessioncodes)
    }
    videocodes$session <- videocodes$Session
    totaldata <- merge(data,videocodes,by=c("session","time"),all=T)
    save(totaldata, file=cleandatafile)
}

```

### A: From samples to episodes

We first calculate the _coarse load index_ (how many measures are over the median) and the _fine load index_ (average of percentiles of the different load metrics), and we plot them for each session

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
setwd(paste(rootdir,"/data/study1",sep=""))
totaldata <- get(load(cleandatafile))
loaddata <- calculateCoarseFineLoadIndex(totaldata,normalized=T) # We ensure that the values are normalized for those of the first window in which little load is assumed (just putting the eyetracker on)

# We plot the loads for each session, along with some smoothing

```




## The End!

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# We come to the root folder, for the next study
setwd(rootdir)
```
