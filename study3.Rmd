# Study 3: Comparing Orchestration with Usual and Novel Technology (Primary School)

In this case study, we aimed to explore the following research questions: _How does the subjective measurement of cognitive load relate to the eye-tracking measures of cognitive load taken in an authentic setting? Can we detect specific classroom interaction episodes that imply high (or low) cognitive load? Can we see differences between the orchestration load patterns of a teacher using her usual technology, and a novel technology?_.

The **context** of the data gathering were four sessions of around 80 minutes each, in two different cohorts of 22-23 secondary school students (aged 11-12 years old). In the first two sessions, students were were working (individually or in pairs) with their laptops on a project about geometry. In the second pair of sessions, students were using tangible paper-based tabletops to play a collaborative/competitive game about geometry, in which group-level activities are alternated with class-level resolution and explanations. In all four sessions, the (expert) teacher was wearing a mobile eye-tracker while she facilitated the sessions.

## Before starting: Data download and pre-process

First of all, we download the datasets for the study, which has been published in Zenodo: 

* TODO: Upload to zenodo and post here the link!

```{r, message=FALSE, warning=FALSE, echo=FALSE}
library(ggplot2)
# We load the useful scripts and packages needed throughout the report
source("./lib/rollingWindows.R")
source("./lib/loadIndex.R")
source("./lib/extremeLoadExtraction.R")
source("./lib/aggregateEpisodeData.R")
source("./lib/multiplot.R")
source("./lib/outliers.R")
source('./lib/codeAnalyses.R')
source('./lib/generateVideoSnippetScript.R')
rootdir <- getwd()

# If not present already, download dataset study 3 and uncompress it to Study3/
setwd(paste(rootdir,"/data/study3",sep=""))
if(!file.exists("ISL2014BASELINE-QuestionnaireData.zip") ||
   !file.exists("ISL2015BASELINE-CodingData.zip") ||
   !file.exists("ISL2014BASELINE-EyetrackingData.zip")){ #TODO: Add the other 3 files too!
    download.file("https://zenodo.org/record/16551/files/ISL2014BASELINE-QuestionnaireData.zip", destfile="ISL2014BASELINE-QuestionnaireData.zip", method="curl")
    unzip("ISL2014BASELINE-QuestionnaireData.zip")
    download.file("https://zenodo.org/record/16551/files/ISL2015BASELINE-CodingData.zip", destfile="ISL2015BASELINE-CodingData.zip", method="curl")
    unzip("ISL2015BASELINE-CodingData.zip")
    download.file("https://zenodo.org/record/16551/files/ISL2014BASELINE-EyetrackingData.zip", destfile="ISL2014BASELINE-EyetrackingData.zip", method="curl")
    unzip("ISL2014BASELINE-EyetrackingData.zip")
    
    #TODO: Do the same once the data for ISL2015 is in zenodo
    
} 

# Now we should have the raw data files uncompressed in the data/study3 folder
```

Once we have the raw data from the eye-tracker (plus the video coding data generated by researchers and the responses to the subjective ratings of cognitive load), we pre-process it, mostly by aggregating the four load-related eyetracking metrics (pupil diameter mean, pupil diameter variation, saccade speed and number of fixations >500ms) into 10-second episodes, using a rolling window with 5-second slide between windows (see ```./lib/aggregateEpisodeData.R``` and ```./lib/rollingWindows.R``` files for details).

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
setwd(paste(rootdir,"/data/study3",sep=""))

# We do the preprocessing, which will generate a Rda file with the 10s
# window data, and will return the name of the file

sessions <-  c("ISL2014BASELINE-Session1-eyetracking","ISL2014BASELINE-Session2-eyetracking","ISL2015NOVEL-Session3-eyetracking","ISL2015NOVEL-Session4-eyetracking")

srdata <- data.frame()

cleandatafile <- "study3ProcessedData.Rda"
#if(!file.exists(cleandatafile)){
    data <- aggregateEpisodeData(sessions, datadir=paste(rootdir,"/data/study3",sep=""), initendtimes=NULL, SEPARATOR=";") # For this study the raw data is semicolon-separated, at least the fixation/saccades!
    data <- data[,c(1:5,12)] # We select only the load-related metrics
    # We load and add the video coding data with the social, activity and main gaze focus dimensions
    # clean and put all videocoding data into a single file
    videocodes1 <- read.csv("ISL2014BASELINE-videocoding.csv", sep=",")
    videocodes1$session <- videocodes1$Session
    snippets1 <- read.csv("ISL2014BASELINE-stimulatedrecall-snippetselection.csv", sep=",")
    ratings1 <- read.csv("ISL2014BASELINE-stimulatedrecall-ratings.csv", sep=",")
    srdata1 <- merge(snippets1, ratings1, by=c("Session", "Snippet"),all=T)
    audiocodes1 <- read.csv("ISL2014BASELINE-stimulatedrecall-audiocoding.csv", sep=";")
    audiocodes1$time <- audiocodes1$Eyetrack.Time
    srdata1$time <- srdata1$Window.Center
    srdata1 <- merge(srdata1,audiocodes1,by=c("Session","time","Snippet"),all=T)
    srdata1$session <- srdata1$Session
    srdata1 <- srdata1[,c(2,3,6,8,9,10,13)] # We keep only non-duplicated, useful columns

    videocodes2 <- read.csv("ISL2015NOVEL-videocoding.csv", sep=",")[,-9]
    videocodes2$session <- videocodes2$Session
    snippets2 <- read.csv("ISL2015NOVEL-stimulatedrecall-snippetselection.csv", sep=",")
    ratings2 <- read.csv("ISL2015NOVEL-stimulatedrecall-ratings.csv", sep=",")
    srdata2 <- merge(snippets2, ratings2, by=c("Session", "Snippet"),all=T)
    audiocodes2 <- read.csv("ISL2015NOVEL-stimulatedrecall-audiocoding.csv", sep=";")[1:32,]
    audiocodes2$time <- audiocodes2$Eyetrack.Time
    srdata2$time <- srdata2$Window.Center
    srdata2 <- merge(srdata2,audiocodes2,by=c("Session","time","Snippet"),all=T)
    srdata2$session <- srdata2$Session
    srdata2 <- srdata2[,c(2,3,6,8,9,10,13)] # We keep only non-duplicated, useful columns
    
    videocodes <- rbind(videocodes1,videocodes2)
    srdata <- rbind(srdata1,srdata2)
    totaldata <- merge(data,videocodes,by=c("session","time"),all=T)
    totaldata <- merge(totaldata,srdata,by=c("session","time"),all=T)
    save(totaldata, file=cleandatafile)
#}

```

### A: From samples to episodes

We first calculate the _coarse load index_ (how many measures are over the median) and the _fine load index_ (average of percentiles of the different load metrics), and we plot them for each session

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=3, fig.width=8}
setwd(paste(rootdir,"/data/study3",sep=""))
totaldata <- get(load(cleandatafile))

# In case there are missing values (sp. in the saccade speed), we remove them
totaldata <- totaldata[complete.cases(totaldata$value.Sac),]
# We crop outliers in the saccade speed. They tend to throw off the HMM and PCA calculations
#countOutliers(totaldata$value.Sac,coef = 20, method="iqr") # IQR is quite small (0.06), but there are quite a few samples outside this range, we make it 20xIQR
totaldata$value.Sac <- replaceOutliers(totaldata$value.Sac,valueNA = F,coef = 20, method="iqr")

loaddata <- calculateCoarseFineLoadIndex(totaldata,3:6,normalize=T) # We ensure that the values are normalized for those of the first window in which little load is assumed (just putting the eyetracker on)

# Check that all load metrics are directly proportional (e.g., EEG Theta is inverse to cognitive load). If not, we need to introduce a modification in the calculations of load

# We plot the loads for each session, along with some smoothing
for(session in sessions){
    sessiondata <- loaddata[loaddata$session==session,]
    p1 <- ggplot(sessiondata, aes(x=time, y=CoarseLoad, col=CoarseLoad)) + 
            ggtitle(paste("Coarse Load Index ",session,sep="")) + 
            geom_line(size=1) + stat_smooth(method="loess",span=0.1,se=F) +
            #theme(axis.text.x = element_text(size=18),plot.title=element_text(size=20, face="bold"),axis.title=element_text(size=18),panel.background = element_rect(fill = 'white')) +
            theme(panel.background = element_rect(fill = 'white')) +
            scale_color_gradient(low="green",high="red")
    print(p1)

    p2 <- ggplot(sessiondata, aes(x=time, y=FineLoad, col=FineLoad)) + 
            ggtitle(paste("Fine Load Index ",session,sep="")) + 
            geom_line(size=1) + stat_smooth(method="loess",span=0.1,se=F) +
            #theme(axis.text.x = element_text(size=18),plot.title=element_text(size=20, face="bold"),axis.title=element_text(size=18),panel.background = element_rect(fill = 'white')) +
            theme(panel.background = element_rect(fill = 'white')) +
            scale_color_gradient(low="green",high="red")
    print(p2)
}
```

### B: Exploring the structure of the sensor (episode) load data 


First, we see how the different metrics correlate among themselves:

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=5, fig.width=5}

library(corrplot)
M <- cor(loaddata[, c(3:6)])
corrplot.mixed(M)
```

We do a Principal Component analysis to see what dimensions are there within these 4 load-related signals:

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=5, fig.width=5}

library(FactoMineR)

# Overall for the three sessions
res.pca = PCA(loaddata[, c(3:6)], scale.unit=TRUE, ncp=5, graph=F)
plot.PCA(res.pca, axes=c(1, 2), choix="var", title="Overall data")
#loaddata$PupilLoadDim = res.pca$ind$coord[,1]
#loaddata$EyeMoveFixLoadDim = res.pca$ind$coord[,2]

# We now do it per session, to see if the teacher has different patterns... it does, somehow! The usual ones are kind of similar, but the Novel ones are quite different
 for(session in sessions){
     sessiondata <- loaddata[loaddata$session==session,]
     res.pca = PCA(sessiondata[, c(3:6)], scale.unit=TRUE, ncp=5, graph=F)
     print(plot.PCA(res.pca, axes=c(1, 2), choix="var",title = paste("Session",session)))
 }

# Let us look at the usual vs novel sessions
# Usual sessions
usualdata <- loaddata[loaddata$session==sessions[1] | loaddata$session==sessions[2],]
res.pca = PCA(usualdata[, c(3:6)], scale.unit=TRUE, ncp=5, graph=F)
print(plot.PCA(res.pca, axes=c(1, 2), choix="var",title = "Usual technology"))
usualdata$SacVarLoadDim = res.pca$ind$coord[,1]
usualdata$PupilVsFixLoadDim = res.pca$ind$coord[,2]

# Novel sessions... the dimensions are kind of similar, but dimensions 1 and 2 are exchanged in importance
noveldata <- loaddata[loaddata$session==sessions[3] | loaddata$session==sessions[4],]
res.pca = PCA(noveldata[, c(3:6)], scale.unit=TRUE, ncp=5, graph=F)
print(plot.PCA(res.pca, axes=c(1, 2), choix="var",title = "Novel technology"))
noveldata$SacVarLoadDim = res.pca$ind$coord[,2]
noveldata$PupilVsFixLoadDim = res.pca$ind$coord[,1]
noveldata3 <- noveldata[noveldata$session==sessions[3],]
noveldata4 <- noveldata[noveldata$session==sessions[4],]

```

Interestingly, we can see that the two main dimensions of the load metric variability follows a different pattern to the previous study: in one dimension the saccade speed and the pupil diameter variation are aligned, while in the other the pupil mean and the long fixations are _opposed_. This seems to be constant across the technologies used, but the importance of dimensions is inverted in the case of novel technology.

To explore the temporal structure of these load-related sensor signals, we train a Hidden Markov Model for each kind of technology used, with 4 states using the load-related signals as observables:

**Note**: after exploratory analysis we find that certain HMM states when analyzing the novel technology sessions, become session-dependent, indicating that **the two novel technology sessions are qualitatively different in the time structure of the load metrics**! This may be related to the fact that in the first of those sessions the teacher was only co-facilitating, while in the last one she was leading the facilitation. Hence, we analyze the HMM states separately for both novel sessions.


```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=5, fig.width=5}
library(depmixS4)

# We remove the missing data, as the HMM library does not like them, apparently
# Not needed, we have no missing data in that sense
#data4hmm <- loaddata[complete.cases(loaddata[,c("value.Mean","value.SD","value.Sac","value.Fix")]),]

numstates <- 4

# Overall -- not meaningful since we see some states are only applicable to some sessions and not others
# set.seed(1)
# #set up the HMM model
# mod <- depmix(list(value.Mean~1,value.SD~1,value.Sac~1,value.Fix~1), data=loaddata, nstates=numstates, family=list(gaussian(),gaussian(),gaussian(),poisson()),ntimes=summary(as.factor(loaddata$session)), verbose=F)
# #fit the model 
# f <- fit(mod, verbose=F)
# #check to see how the state transtion matricies and process mean/sd matches our sample data
# summary(f)
# #get the estimated state for each timestep 
# esttrans <- posterior(f)
# loaddata$MMstate <- esttrans[,1]
# #plot(1:nrow(loaddata), esttrans[,1], type='p', col=as.factor(loaddata$session), main=paste('Estimated state',numstates))
# 
# loaddata$MMstate <- factor(loaddata$MMstate)
# xtabs(~CoarseLoad+MMstate,data=loaddata)
# g1 <- ggplot(data = loaddata, mapping = aes(MMstate, FineLoad))+geom_boxplot(aes(fill=MMstate))+geom_jitter()
# print(g1)
# 
# # We can also plot the states with regard to the two load dimensions from the PCA
# g2 <- ggplot(data = loaddata, mapping = aes(PupilLoadDim,EyeMoveFixLoadDim)) + geom_point(aes(col=MMstate)) + xlim(-4,4) + ylim(-5,5)
# print(g2)
# 
# #State 1/2 seems to be mid/hi load, state 3 is mid load, state 4 is low-load
# levels(loaddata$MMstate) <- c("HiFixLoadState","HiSacLoadState","MidLoadState","LowLoadState")

# Usual tech

# We plot the BIC for different number of states, just to check
states <- 2:16
BICs <- 0
for(i in states){
#    print(paste(numstates,"..."))
    # Overall
    set.seed(1)
    #set up the HMM model
    mod <- depmix(list(value.Mean~1,value.SD~1,value.Sac~1,value.Fix~1), data=usualdata, nstates=i, family=list(gaussian(),gaussian(),gaussian(),poisson()),ntimes=summary(as.factor(usualdata$session)), verbose=F)
    #fit the model 
    f <- fit(mod, verbose=F)
#    print(f)
    BICs[i] <- BIC(f)
}
qplot(1:16,BICs,geom="line")



set.seed(1)
#set up the HMM model
mod <- depmix(list(value.Mean~1,value.SD~1,value.Sac~1,value.Fix~1), data=usualdata, nstates=numstates, family=list(gaussian(),gaussian(),gaussian(),poisson()),ntimes=summary(as.factor(usualdata$session)), verbose=F)
#fit the model 
f <- fit(mod, verbose=F)
#check to see how the state transtion matricies and process mean/sd matches our sample data
summary(f)
#get the estimated state for each timestep 
esttrans <- posterior(f)
usualdata$MMstate <- esttrans[,1]
#plot(1:nrow(usualdata), esttrans[,1], type='p', col=as.factor(usualdata$session), main=paste('Estimated state',numstates))

usualdata$MMstate <- factor(usualdata$MMstate)
xtabs(~CoarseLoad+MMstate,data=usualdata)
g1 <- ggplot(data = usualdata, mapping = aes(MMstate, FineLoad))+geom_boxplot(aes(fill=MMstate))+geom_jitter(aes(col=session))
print(g1)

# We can also plot the states with regard to the two load dimensions from the PCA
g2 <- ggplot(data = usualdata, mapping = aes(SacVarLoadDim,PupilVsFixLoadDim)) + geom_point(aes(col=MMstate))# + xlim(-4,4) + ylim(-5,5)
print(g2)

#State 1/2 seems to be mid/hi load, state 3 is mid load, state 4 is low-load
levels(usualdata$MMstate) <- c("LowLoadState","HiSacVarLoadState","LowMidFixLoadState","HiPupilLoadState")



```

As we can see, for the **usual technology**, State 1 seems to be lower-load, more frequent in one session, while State 3 seems to be low-mid load (more frequent in the other session). State 2 is a quite-infrequent high-load one, while State 4 is a more common high-load state. 

Also, looking at the two dimensions of load from the PCA we see how these states separate quite clearly the load values:

* State 1: low-load, in both dimensions
* State 2: high-load, with very high levels of saccade and pupil variance
* State 3: low-mid load state, with more fixation load
* State 4: high-load, high pupil mean


```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=5, fig.width=5}

# Novel tech 3

# We plot the BIC for different number of states, just to check
states <- 2:16
BICs <- 0
for(i in states){
#    print(paste(numstates,"..."))
    # Overall
    set.seed(1)
    #set up the HMM model
    mod <- depmix(list(value.Mean~1,value.SD~1,value.Sac~1,value.Fix~1), data=noveldata3, nstates=i, family=list(gaussian(),gaussian(),gaussian(),poisson()),ntimes=summary(as.factor(noveldata3$session)), verbose=F)
    #fit the model 
    f <- fit(mod, verbose=F)
#    print(f)
    BICs[i] <- BIC(f)
}
qplot(1:16,BICs,geom="line")


set.seed(3)
#set up the HMM model
mod <- depmix(list(value.Mean~1,value.SD~1,value.Sac~1,value.Fix~1), data=noveldata3, nstates=numstates, family=list(gaussian(),gaussian(),gaussian(),poisson()),ntimes=summary(as.factor(noveldata3$session)), verbose=F)
#fit the model 
f <- fit(mod, verbose=F)
#check to see how the state transtion matricies and process mean/sd matches our sample data
summary(f)
#get the estimated state for each timestep 
esttrans <- posterior(f)
noveldata3$MMstate <- esttrans[,1]
#plot(1:nrow(noveldata3), esttrans[,1], type='p', col=as.factor(noveldata3$session), main=paste('Estimated state',numstates))

noveldata3$MMstate <- factor(noveldata3$MMstate)
xtabs(~CoarseLoad+MMstate,data=noveldata3)
g1 <- ggplot(data = noveldata3, mapping = aes(MMstate, FineLoad))+geom_boxplot(aes(fill=MMstate))+geom_jitter(aes(col=session))
print(g1)

# We can also plot the states with regard to the two load dimensions from the PCA
g2 <- ggplot(data = noveldata3, mapping = aes(SacVarLoadDim,PupilVsFixLoadDim)) + geom_point(aes(col=MMstate))# + xlim(-4,4) + ylim(-5,5)
print(g2)

#State 1/2 seems to be mid/hi load, state 3 is mid load, state 4 is low-load
levels(noveldata3$MMstate) <- c("HiSacVarLoadState","MidHighPupilMeanLoadState","MidLowPupilMeanLoadState","MidLoadState")



```

As we can see, for the **first session of novel technology**, State 1 seems to be a high-load one, and State 2 is a wider varying mid-high state. State 3 is more of a midlow load state, and state 4 seems to be more of a mid-load state. 

Also, looking at the two dimensions of load from the PCA we see how these states separate better the load values, even if not very neatly:

* State 1: High-load state, more oriented towards saccade and pupil variation
* State 2: High-load state, more oriented towards pupil diameter mean
* State 3: Mid-Low-load state, more emphases on Pupil diameter mean
* State 4: Mid-load state


```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=5, fig.width=5}

# Novel tech 4

# TODO: Check this data... the hmm crashes!
# # We plot the BIC for different number of states, just to check
# hmmdata <- noveldata4[complete.cases(noveldata4[,c("value.Mean","value.SD","value.Sac","value.Fix")]),]
# states <- 2:16
# BICs <- 0
# for(i in states){
# #    print(paste(numstates,"..."))
#     # Overall
#     set.seed(55)
#     #set up the HMM model
#     mod <- depmix(list(value.Mean~1,value.SD~1,value.Sac~1,value.Fix~1), data=hmmdata, nstates=i, family=list(gaussian(),gaussian(),gaussian(),poisson()),ntimes=summary(as.factor(hmmdata$session)), verbose=F)
#     #fit the model 
#     f <- fit(mod, verbose=F)
# #    print(f)
#     BICs[i] <- BIC(f)
# }
# qplot(1:16,BICs,geom="line")


set.seed(6)
#set up the HMM model
mod <- depmix(list(value.Mean~1,value.SD~1,value.Sac~1,value.Fix~1), data=noveldata4, nstates=numstates, family=list(gaussian(),gaussian(),gaussian(),poisson()),ntimes=summary(as.factor(noveldata4$session)), verbose=F)
#fit the model 
f <- fit(mod, verbose=F)
#check to see how the state transtion matricies and process mean/sd matches our sample data
summary(f)
#get the estimated state for each timestep 
esttrans <- posterior(f)
noveldata4$MMstate <- esttrans[,1]
#plot(1:nrow(noveldata4), esttrans[,1], type='p', col=as.factor(noveldata4$session), main=paste('Estimated state',numstates))

noveldata4$MMstate <- factor(noveldata4$MMstate)
xtabs(~CoarseLoad+MMstate,data=noveldata4)
g1 <- ggplot(data = noveldata4, mapping = aes(MMstate, FineLoad))+geom_boxplot(aes(fill=MMstate))+geom_jitter(aes(col=session))
print(g1)

# We can also plot the states with regard to the two load dimensions from the PCA
g2 <- ggplot(data = noveldata4, mapping = aes(SacVarLoadDim,PupilVsFixLoadDim)) + geom_point(aes(col=MMstate))# + xlim(-4,4) + ylim(-5,5)
print(g2)

#State 1/2 seems to be mid/hi load, state 3 is mid load, state 4 is low-load
levels(noveldata4$MMstate) <- c("MidLowFixLoadState","LowLoadState","MidHiFixLoadState","HighLoadState")

```

As we can see, for the **second session of novel technology**, state 1 seems to be a mid-low, state 2 a low one, state 3 a mid-high one, and state 4 a rare, high-load one.

Also, looking at the two dimensions of load from the PCA we see how these states separate better the load values, even if not very neatly:

* State 1: Mid-low-load state, more oriented towards fixations
* State 2: Low state
* State 3: Mid-load state, also oriented towards fixations
* State 4: High-load state


### C: Subjective episode analysis

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE, eval=F}
# Code to generate the video snippets to use in the stimulated recall interview
# This assumes the videos are placed in the same location as the dataset
generateVideoSnippetScript(timesFile=paste(rootdir,"/data/study3/ISL2014BASELINE-stimulatedrecall-snippetselection.csv",sep=""),videoDir=".")
# Then, the generated script (extractSnippets.sh) has to be executed to generate the small video files for each selected episode
generateVideoSnippetScript(timesFile=paste(rootdir,"/data/study3/ISL2015NOVEL-stimulatedrecall-snippetselection.csv",sep=""),videoDir=".")
# Idem
```

To understand how these physiological measures of cognitive load relate with the subjective experience and perception of mental effort, we analyze the episode ratings and think-aloud rationales of the teacher, and compare them with the physiological load values:

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=5, fig.width=10}
library(gplots)

compare <- rbind(usualdata[,c("CoarseLoad","FineLoad","Subjective.Value","Codes","SacVarLoadDim","PupilVsFixLoadDim","MMstate","session")],noveldata3[,c("CoarseLoad","FineLoad","Subjective.Value","Codes","SacVarLoadDim","PupilVsFixLoadDim","MMstate","session")],noveldata4[,c("CoarseLoad","FineLoad","Subjective.Value","Codes","SacVarLoadDim","PupilVsFixLoadDim","MMstate","session")])
compare <- compare[complete.cases(compare),]

names(compare)

compare$sessionkind <- ifelse((compare$session==sessions[1] | compare$session==sessions[2]), "Usual", "Novel")
qplot(Subjective.Value, FineLoad, data = compare, geom=c("point","smooth"), method="lm", col=sessionkind)

print("Usual sessions")
summary(lm(FineLoad~Subjective.Value,data = compare[compare$sessionkind=="Usual",]))
print("Novel sessions")
summary(lm(FineLoad~Subjective.Value,data = compare[compare$sessionkind=="Novel",]))



codes <- flattenCodeData(compare,4,c(1:3,5:9))

# General DISTRIBUTION OF CODES
qplot(Code,data=codes,fill=session)

qplot(Code,data=codes,fill=sessionkind)+coord_flip()


# COMPARISON AGAINST PHYSIOLOGICAL VALUES
plotmeans(Subjective.Value ~ CoarseLoad, data=compare)
# We check the significance of this difference
anova(lm(compare$Subjective.Value~compare$CoarseLoad))$`Pr(>F)`[1]

qplot(Subjective.Value,FineLoad, data=compare, geom=c("point"))+geom_smooth(se=T,method="lm")
# We check the significance of this difference
anova(lm(compare$Subjective.Value~compare$FineLoad))$`Pr(>F)`[1]

# COMPARISON OF CODES AND SUBJECTIVE/PHYSIOLOGICAL VALUES
# Codes vs. Subj.Load ... what proportion of codes are in the high part of the teacher's subjective range of values?
codes$Subjective.Hi <- codes$Subjective.Value > mean(range(codes$Subjective.Value))
subjtab <- xtabs(~Subjective.Hi+Code, data=codes)
subjtab
chisq.test(subjtab)
chisq.test(subjtab)$residuals

# Codes vs. Load... no statistically significant trend
qplot(Code,FineLoad,data=codes,geom="boxplot",fill=Code)+geom_jitter()
codes$Fine.Hi <- codes$FineLoad > mean(range(codes$FineLoad))
finetab <- xtabs(~Fine.Hi+Code, data=codes)
finetab
chisq.test(finetab)
coarsetab <- xtabs(~factor(CoarseLoad)+Code, data=codes)
coarsetab
chisq.test(coarsetab)

# Codes vs. PCA dimensions... no statistically significant trend
qplot(Code,SacVarLoadDim,data=codes,geom="boxplot",fill=Code)+geom_jitter()+ylim(c(-2,2))
qplot(Code,PupilVsFixLoadDim,data=codes,geom="boxplot",fill=Code)+geom_jitter()

# Codes vs. HMM states... no statistically significant trend
hmmtab <- xtabs(~MMstate+Code, data=codes)
hmmtab
chisq.test(coarsetab)
```

For the **overall analysis** of this subjective data, we find that the codes are a bit different in both kinds of sessions, and that the correlation between the physiological load and the subjective ratings is negligible.

Although not significant, there is a clear trend to make remarks about following progress/plans and making repairs in the lower subjective ratings, while putting anticipation, guiding or game-specific, frustration or class-wide in the higher-load ratings.

Let us now do the same for the Usual and novel technology sessions separately, to see whether there are noticeable differences

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=5, fig.width=10}
library(gplots)

compare <- usualdata[,c("CoarseLoad","FineLoad","Subjective.Value","Codes","SacVarLoadDim","PupilVsFixLoadDim","MMstate")]
compare <- compare[complete.cases(compare),]
names(compare)
codes <- flattenCodeData(compare,4,c(1:3,5:7))

# General DISTRIBUTION OF CODES
qplot(Code,data=codes,fill=Code)

# COMPARISON AGAINST PHYSIOLOGICAL VALUES
plotmeans(Subjective.Value ~ CoarseLoad, data=compare)
# We check the significance of this difference
anova(lm(compare$Subjective.Value~compare$CoarseLoad))$`Pr(>F)`[1]

qplot(Subjective.Value,FineLoad, data=compare, geom=c("point"))+geom_smooth(se=T,method="lm")
# We check the significance of this difference
anova(lm(compare$Subjective.Value~compare$FineLoad))$`Pr(>F)`[1]

# COMPARISON OF CODES AND SUBJECTIVE/PHYSIOLOGICAL VALUES
# Codes vs. Subj.Load ... what proportion of codes are in the high part of the teacher's subjective range of values?
codes$Subjective.Hi <- codes$Subjective.Value > mean(range(codes$Subjective.Value))
subjtab <- xtabs(~Subjective.Hi+Code, data=codes)
subjtab
chisq.test(subjtab)

# Codes vs. Load... no statistically significant trend
qplot(Code,FineLoad,data=codes,geom="boxplot",fill=Code)+geom_jitter()
codes$Fine.Hi <- codes$FineLoad > mean(range(codes$FineLoad))
finetab <- xtabs(~Fine.Hi+Code, data=codes)
finetab
chisq.test(finetab)
coarsetab <- xtabs(~factor(CoarseLoad)+Code, data=codes)
coarsetab
chisq.test(coarsetab)

# Codes vs. PCA dimensions... no statistically significant trend
qplot(Code,SacVarLoadDim,data=codes,geom="boxplot",fill=Code)+geom_jitter()
qplot(Code,PupilVsFixLoadDim,data=codes,geom="boxplot",fill=Code)+geom_jitter()

# Codes vs. HMM states... no statistically significant trend
hmmtab <- xtabs(~MMstate+Code, data=codes)
hmmtab
chisq.test(coarsetab)
```


For the **usual technology sessions**, we see that _modelling, assessing and following the progress_ of students are the most common aspects mentioned regarding (subjective) mental effort. We find a quite noticeable correspondence between physiological and subjective load ratings (p=0.02). 

Regarding the distribution of codes in different kinds of episodes, we find that the _teacher tends to mention modelling (and assessing and following progress) in the episodes she rates higher in mental effort_, but the difference is not significant (sample size is too small). When comparing with the physiological measures of load, however, these trends are less noticeable (sp. given the small sample size): Assessing and modelling seem to be equally present in both high and low-load episodes. Hence, it looks like the _rationales for rating mental effort do not relate much with the physiological measures_ taken.


```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=5, fig.width=10}
library(gplots)

compare <- rbind(noveldata3[,c("CoarseLoad","FineLoad","Subjective.Value","Codes","SacVarLoadDim","PupilVsFixLoadDim","MMstate","session")],noveldata4[,c("CoarseLoad","FineLoad","Subjective.Value","Codes","SacVarLoadDim","PupilVsFixLoadDim","MMstate","session")])
compare <- compare[complete.cases(compare$Subjective.Value),]
names(compare)
codes <- flattenCodeData(compare,4,c(1:3,5:8))

# General DISTRIBUTION OF CODES
qplot(Code,data=codes,fill=session)

# COMPARISON AGAINST PHYSIOLOGICAL VALUES
plotmeans(Subjective.Value ~ CoarseLoad, data=compare)
# We check the significance of this difference
anova(lm(compare$Subjective.Value~compare$CoarseLoad))$`Pr(>F)`[1]

qplot(Subjective.Value,FineLoad, data=compare, geom=c("point"))+geom_smooth(se=T,method="lm")
# We check the significance of this difference
anova(lm(compare$Subjective.Value~compare$FineLoad))$`Pr(>F)`[1]

#What about separating the sessions?
qplot(Subjective.Value,FineLoad, data=compare, geom=c("point"), col=session)+geom_smooth(se=T,method="lm")
compare3 <- compare[compare$session==sessions[3],]
compare4 <- compare[compare$session==sessions[4],]
# We check the significance of this difference
anova(lm(compare3$Subjective.Value~compare3$FineLoad))$`Pr(>F)`[1]
anova(lm(compare4$Subjective.Value~compare4$FineLoad))$`Pr(>F)`[1]

# COMPARISON OF CODES AND SUBJECTIVE/PHYSIOLOGICAL VALUES
# Codes vs. Subj.Load ... what proportion of codes are in the high part of the teacher's subjective range of values?
codes$Subjective.Hi <- codes$Subjective.Value > mean(range(codes$Subjective.Value))
subjtab <- xtabs(~Subjective.Hi+Code, data=codes)
subjtab
chisq.test(subjtab)

# Codes vs. Load... no statistically significant trend
qplot(Code,FineLoad,data=codes,geom="boxplot",fill=Code)+geom_jitter(aes(col=session))
#qplot(Code,FineLoad,data=codes,geom="boxplot",fill=session)+geom_jitter(aes(col=session))
codes$Fine.Hi <- codes$FineLoad > mean(range(codes$FineLoad))
finetab <- xtabs(~Fine.Hi+Code, data=codes)
finetab
chisq.test(finetab)
coarsetab <- xtabs(~factor(CoarseLoad)+Code, data=codes)
coarsetab
chisq.test(coarsetab)

# Codes vs. PCA dimensions... no statistically significant trend
qplot(Code,SacVarLoadDim,data=codes,geom="boxplot",fill=Code)+geom_jitter(aes(col=session))
qplot(Code,PupilVsFixLoadDim,data=codes,geom="boxplot",fill=Code)+geom_jitter(aes(col=session))

# Codes vs. HMM states... no statistically significant trend
hmmtab <- xtabs(~MMstate+Code, data=codes)
hmmtab
chisq.test(coarsetab)
```

For the **novel technology sessions**, we find that still assessing, modelling and monitoring are among the most common issues mentioned in the subjective rationales; however, in this case there are also a lot of game-specific remarks (rules of the game, etc). There are also a few mentions to frustration in the last session.

However, in this case we observe that the subjective and physiological ratings of load are not clearly correlated (maybe because of the novelty of the situation?). However, we also see that this is mostly due to the first novel session, in which correlation is actually negative, while in the last session it is positive (but not statistically significant).

Regarding the distribution of codes, even if trends are not statistically significant (given their small number), there are certain trends of putting modelling and assessing and guiding, anticipation (and game-specific) in the higher subjective values.

Interestingly, the (non-statistically significant) trends in terms of physiological load are reversed: modelling, assessing, monitoring tend to be in the lower part of the physiological load, while anticipation remains in the high load part. Also interesting (although not part of the subjective opinion rather the snippet selection, most episodes in the first novel session are towards the pupil mean load metric, while on the second novel session they are mostly towards the long fixation dimension)

**Differences between usual and novel technology sessions**
From the above comparisons, we can see how the teacher tends to be consistent in the rationales for responses (e.g., assessing, modelling being in the high mental effort episodes), while the physiological readings of load are less consistent with the rationales (e.g., assessing monitoring being unrelated in the usual sessions, while they tend to be in the low-load part of the spectrum in the novel technology sessions). Also, we see that the subjective values correlate with the physiological ones... but not in the novel situations (but more data would be needed to confirm)

### D: Behavioral episode analysis

From the coarse load index, we extracted the extreme load episodes (10-second episodes with a coarse load index of 0 or 4), for manual coding of the subjective video feed by a researcher (see the ```./lib/extremeLoadExtraction.R``` file).

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
outputfile <- paste(rootdir,"/data/study3/TimesToVideoCode.csv",sep="")
extremedata <- extractExtremeLoadMoments(sessions, loaddata, outputfile)
```

We manually coded the videos of all these extreme load episodes, along the dimensions of teacher activity, social plane of the interaction and main focus of gaze (see the ```ISL*-videocoding.csv``` datafiles). We then aggregate the code counts for each of these dimensions, to bridge from the episode-level analysis to have an idea of what kind of episodes are often high or low (coarse/fine) load. Also, comparisons with fine load, and the PCA and HMM dimensions of load data are made.

#### Activity dimension

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
# Overall behavioral analyses
# ACTIVITY
loaddata <- rbind(usualdata,noveldata3,noveldata4)

behdata <- loaddata[((loaddata$CoarseLoad==0 | loaddata$CoarseLoad==4) & !is.na(loaddata$Activity)),]
#behdata <- loaddata[!is.na(loaddata$Activity),]
behdata$Activity <- factor(behdata$Activity)
# chi-squared test and counts/residuals table for teacher activity
tabAct <- table(behdata$CoarseLoad,behdata$Activity)
chisq.test(tabAct)
tabAct
chisq.test(tabAct)$residuals

# Plotting against the FineLoad confirms the trends of CoarseLoad (even with its tendency towards the mean)
g1 <- ggplot(loaddata[!is.na(loaddata$Activity),],aes(Activity,FineLoad)) + geom_boxplot(aes(fill=Activity)) + geom_jitter(aes(col=session))
print(g1)
# Density plots for the PCA dimensions for each kind of activity
# g1 <- ggplot(loaddata[!is.na(loaddata$Activity),],aes(SacVarLoadDim)) + geom_density(aes(col=Activity))
# print(g1)
# g2 <- ggplot(loaddata[!is.na(loaddata$Activity),],aes(PupilVsFixLoadDim)) + geom_density(aes(col=Activity))
# print(g2)
# Another way of seeing this, in the PCA diagram
res.pca = PCA(loaddata[, c(3:6, 12)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=5)
#plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5)
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5, invisible="ind")

# Comparison against the HMM states of load -- The states are different for each session, almost!
hmmActTab <- xtabs(~Activity+MMstate, data=loaddata[!is.na(loaddata$Activity),])
chisq.test(hmmActTab)
hmmActTab
chisq.test(hmmActTab)$residuals

```

Looking at the overall data, we find that **Activity** seems related to the coarse load, and we see how EXPlanations and QUEstioning are higher-load, while REPairs or MONitoring tend to be lower load. EXPlanations tend to be heavier in the saccade/pupil variance dimension, while DISCiplinary remarks tend to be bigger in terms of fixation (but they are too few to tell for sure).

Looking into the PCA load dimensions, we see that EXP and QUE are heavier in the saccade/variation dimension, with MON, TDT and especially REP being low on this. The bariatiions in the pupil mean vs fixation dimension are relatively small.

Looking at the HMM states, we find that certain activities are clearly represented in some states: EXPlanations tend to be in the high-load, high pupil mean state. MON tends to be in mid-low load states. QUE tends to be in high-load, high pupil mean state; REP tends to be in low or low-mid fixation states; TDT tends to be in the mid-low state with higher pupil mean.

Let us now look at the activity analyses for the usual and novel sessions, to see whether there are noticeable differences.

_Hence, we see that, despite the teacher being an expert, load patterns with regard to activity can be observed_

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
# Usual tech analyses
# ACTIVITY
# Additional non-extreme episodes were also coded, we eliminate them to get the coarse load contrast
#behdata <- usualdata[(!is.na(usualdata$Activity)),]
behdata <- usualdata[((loaddata$CoarseLoad==0 | loaddata$CoarseLoad==4) & !is.na(loaddata$Activity)),]
behdata$Activity <- factor(behdata$Activity)
# chi-squared test and counts/residuals table for teacher activity
tabAct <- table(behdata$CoarseLoad,behdata$Activity)
chisq.test(tabAct)
tabAct
chisq.test(tabAct)$residuals

# Plotting against the FineLoad
g1 <- ggplot(usualdata[!is.na(usualdata$Activity),],aes(Activity,FineLoad)) + geom_boxplot(aes(fill=Activity))
print(g1)
# Density plots for the PCA dimensions for each kind of activity
# g1 <- ggplot(usualdata[!is.na(usualdata$Activity),],aes(SacVarLoadDim)) + geom_density(aes(col=Activity))
# print(g1)
# g2 <- ggplot(usualdata[!is.na(usualdata$Activity),],aes(PupilVsFixLoadDim)) + geom_density(aes(col=Activity))
# print(g2)
# Another way of seeing this, in the PCA diagram
res.pca = PCA(usualdata[, c(3:6, 12)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=5)
#plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5)
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5, invisible="ind")

# Comparison against the HMM states of load -- This was not really done for overall data
usualdata$Activity <- factor(usualdata$Activity)
hmmActTab <- xtabs(~Activity+MMstate, data=usualdata[!is.na(usualdata$Activity),])
chisq.test(hmmActTab)
hmmActTab
chisq.test(hmmActTab)$residuals

```

The **Activity** distribution is very unlikely to be independent of the physiological load. EXP, QUE tend to be high load, and REP (and somehow less MON) tend to be lower load. The trends in the PCA dimensions are similar to those in the overall analysis, with rather small differences among activities.

The comparison with the HMM states clearly mark REP as being mostly in the low-load state, EXP in the high-load pupil mean state, and QUE in the high-load saccade/variance state.

Thus we see that, maybe, _the activities being done are affecting quite clearly the expert teacher_.


```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
# Novel tech analyses
# ACTIVITY
#behdata <- noveldata[(!is.na(noveldata$Activity)),]
behdata <- noveldata[((noveldata$CoarseLoad==0 | noveldata$CoarseLoad==4) & !is.na(noveldata$Activity)),]
# If we want to separate the two sessions of novel tech
# behdata3 <- noveldata3[(!is.na(noveldata3$Activity)),]
# behdata4 <- noveldata4[(!is.na(noveldata4$Activity)),]
behdata3 <- noveldata3[((noveldata3$CoarseLoad==0 | noveldata3$CoarseLoad==4) & !is.na(noveldata3$Activity)),]
behdata4 <- noveldata4[((noveldata4$CoarseLoad==0 | noveldata4$CoarseLoad==4) & !is.na(noveldata4$Activity)),]

behdata$Activity <- factor(behdata$Activity)
behdata3$Activity <- factor(behdata3$Activity)
behdata4$Activity <- factor(behdata4$Activity)

# chi-squared test and counts/residuals table for teacher activity
tabAct <- table(behdata$CoarseLoad,behdata$Activity)
chisq.test(tabAct)
tabAct
chisq.test(tabAct)$residuals

tabAct3 <- table(behdata3$CoarseLoad,behdata3$Activity)
chisq.test(tabAct3)
tabAct3
chisq.test(tabAct3)$residuals
tabAct4 <- table(behdata4$CoarseLoad,behdata4$Activity)
chisq.test(tabAct4)
tabAct4
chisq.test(tabAct4)$residuals


# Plotting against the FineLoad is not very revealing, as we took extreme values and the averages will always be around the average values!
#g1 <- ggplot(noveldata[!is.na(noveldata$Activity),],aes(Activity,FineLoad)) + geom_boxplot(aes(fill=Activity))
#print(g1)
# Density plots for the PCA dimensions for each kind of activity
#g1 <- ggplot(noveldata[!is.na(noveldata$Activity),],aes(PupilLoadDim)) + geom_density(aes(col=Activity))
#print(g1)
#g2 <- ggplot(noveldata[!is.na(noveldata$Activity),],aes(EyeMoveFixLoadDim)) + geom_density(aes(col=Activity))
#print(g2)
# Another way of seeing this, in the PCA diagram
res.pca = PCA(noveldata[, c(3:6, 12)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=5)
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5, invisible="ind")
res.pca = PCA(noveldata3[, c(3:6, 12)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=5)
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5, invisible="ind")
res.pca = PCA(noveldata4[, c(3:6, 12)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=5)
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5, invisible="ind")


# Comparison against the HMM states of load -- This was not really done for overall data
noveldata3$Activity <- factor(noveldata3$Activity)
hmmActTab <- xtabs(~Activity+MMstate, data=noveldata3[!is.na(noveldata3$Activity),])
chisq.test(hmmActTab)
hmmActTab
chisq.test(hmmActTab)$residuals
noveldata4$Activity <- factor(noveldata4$Activity)
hmmActTab <- xtabs(~Activity+MMstate, data=noveldata4[!is.na(noveldata4$Activity),])
chisq.test(hmmActTab)
hmmActTab
chisq.test(hmmActTab)$residuals

```

In the case of the **novel technology**, we see somehow similar trends to the overall and usual technology cases, but less clearly (e.g., EXP is still high load, but the other activities are not so significantly related). We see that this is due to the differences between the first novel tech session (with clear, similar trends) and the second novel tech session (where trends are unclear).

The PCA dimensions also show us how differences in the main dimension (saccade/variance) are small, while they are quite large in the second on (mean pupil diameter vs. long fixations). Separating the two sessions, we see how EXP tends to be always high-pupil diameter load, but the other activities vary from session to session.

The distribution with respect to HMM states of the two sessions is also slightly different (since the HMM states are also defined differently): in the first novel session, EXP tends to be high-load high-variance state or mid-high load high pupil mean; in the second one EXP is in the high-load state. The other trends are not so important, but they are somehow similar (e.g., TDT tends to be in the mid-low or low-load states).

In any case, as we keep slicing the data, the statistical power decreases so it is more difficult to see trends.

**Comparison of Activity between usual and novel technologies**: Some trends are similar (e.g., EXP is high-load, REP tends to be in low- or low-mid states), but others are clearly different (also because the kinds of activities the teacher did was different -- e.g., almost no QUE in the novel tech sessions)

#### Social dimension

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
# SOCIAL
# Overall analysis
behdata <- loaddata[((loaddata$CoarseLoad==0 | loaddata$CoarseLoad==4) & !is.na(loaddata$Social)),]
behdata$Social <- factor(behdata$Social)
# chi-squared test and counts/residuals table for social plane of interaction
tabSoc <- table(behdata$CoarseLoad,behdata$Social)
chisq.test(tabSoc)
tabSoc
chisq.test(tabSoc)$residuals

# Plotting against the FineLoad is not very revealing, as we took extreme values and the averages will always be around the average values!
g1 <- ggplot(loaddata[!is.na(loaddata$Social),],aes(Social,FineLoad)) + geom_boxplot(aes(fill=Social))
print(g1)
# Density plots for the PCA dimensions for each kind of activity
# g1 <- ggplot(loaddata[!is.na(loaddata$Social),],aes(PupilLoadDim)) + geom_density(aes(col=Social))
# print(g1)
# g2 <- ggplot(loaddata[!is.na(loaddata$Social),],aes(EyeMoveFixLoadDim)) + geom_density(aes(col=Social))
# print(g2)
# Another way of seeing this, in the PCA diagram
res.pca = PCA(loaddata[, c(3:6, 13)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=5)
#plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5)
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5, invisible="ind")

# Comparison against the HMM states of load
hmmSocTab <- xtabs(~Social+MMstate, data=loaddata[!is.na(loaddata$Social),])
chisq.test(hmmSocTab)
hmmSocTab
chisq.test(hmmSocTab)$residuals

```

Analyzing the overall data, the distribution with respect to **Social plane** is statistically significant, and the high-load episodes tend to be more often in the classroom plane, while the low-load tend to be in the individual/group plane. 

However, looking at the two load dimensions, it seems like the GRP and CLSsroom levels are very close together in terms of saccade/variation dimension (and far from INDividual), and that differences in the pupil vs. fixation dimension are small. Probably we need to analyze the data on a technology/session level to see clear trends...

However, the HMM states seem to separate quite well the social levels: IND tend to be in the low-load state, CLS in the high-load or high-load pupil mean states, and GRP in the mid-low states (either high on pupil mean or fixations).

Let us look and compare the results for the different kinds of sessions:

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
# Usual technology
usualdata$Social <- factor(usualdata$Social) # To eliminate nonexistent levels
#behdata <- usualdata[!is.na(usualdata$Social),]
behdata <- usualdata[((usualdata$CoarseLoad==0 | usualdata$CoarseLoad==4) & !is.na(usualdata$Social)),]
behdata$Social <- factor(behdata$Social)
# chi-squared test and counts/residuals table for social plane of interaction
tabSoc <- table(behdata$CoarseLoad,behdata$Social)
chisq.test(tabSoc)
tabSoc
chisq.test(tabSoc)$residuals

# Plotting against the FineLoad is not very revealing, as we took extreme values and the averages will always be around the average values!
g1 <- ggplot(usualdata[!is.na(usualdata$Social),],aes(Social,FineLoad)) + geom_boxplot(aes(fill=Social)) + geom_jitter(aes(col=session))
print(g1)
# Density plots for the PCA dimensions for each kind of activity
# g1 <- ggplot(usualdata[!is.na(usualdata$Social),],aes(PupilLoadDim)) + geom_density(aes(col=Social))
# print(g1)
# g2 <- ggplot(usualdata[!is.na(usualdata$Social),],aes(EyeMoveFixLoadDim)) + geom_density(aes(col=Social))
# print(g2)
# Another way of seeing this, in the PCA diagram
res.pca = PCA(usualdata[, c(3:6, 13)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=5)
#plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5)
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5, invisible="ind")

# Comparison against the HMM states of load
hmmSocTab <- xtabs(~Social+MMstate, data=usualdata[!is.na(usualdata$Social),])
chisq.test(hmmSocTab)
hmmSocTab
chisq.test(hmmSocTab)$residuals

```

In the case of the **usual technology** teacher, the same clear trend of **Social** plane being more class-level in the high-load episodes exists, and individual-lelel in the low-load ones (there were not enough group-level interactions). We see that the differences among both are more prominent in the pupil mean vs fixation dimension. The HMM states clearly indicate the INDividual episodes in a low-load state, and the class-level ones in the high-load, pupil mean state (similar to the PCA dimension results)



```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
# Novel technology analysis
noveldata$Social <- factor(noveldata$Social) # To eliminate nonexistent levels
noveldata3$Social <- factor(noveldata3$Social) # To eliminate nonexistent levels
noveldata4$Social <- factor(noveldata4$Social) # To eliminate nonexistent levels

# behdata <- noveldata[(!is.na(noveldata$Social)),]
# behdata3 <- noveldata3[(!is.na(noveldata3$Social)),]
# behdata4 <- noveldata4[(!is.na(noveldata4$Social)),]
behdata <- noveldata[((noveldata$CoarseLoad==0 | noveldata$CoarseLoad==4) & !is.na(noveldata$Social)),]
behdata3 <- noveldata3[((noveldata3$CoarseLoad==0 | noveldata3$CoarseLoad==4) & !is.na(noveldata$Social)),]
behdata4 <- noveldata4[((noveldata4$CoarseLoad==0 | noveldata4$CoarseLoad==4) & !is.na(noveldata4$Social)),]

behdata$Social <- factor(behdata$Social)
behdata3$Social <- factor(behdata3$Social)
behdata4$Social <- factor(behdata4$Social)
# chi-squared test and counts/residuals table for social plane of interaction
tabSoc <- table(behdata$CoarseLoad,behdata$Social)
chisq.test(tabSoc)
tabSoc
chisq.test(tabSoc)$residuals
tabSoc <- table(behdata3$CoarseLoad,behdata3$Social)
chisq.test(tabSoc)
tabSoc
chisq.test(tabSoc)$residuals
tabSoc <- table(behdata4$CoarseLoad,behdata4$Social)
chisq.test(tabSoc)
tabSoc
chisq.test(tabSoc)$residuals


# Plotting against the FineLoad is not very revealing, as we took extreme values and the averages will always be around the average values!
g1 <- ggplot(noveldata[!is.na(noveldata$Social),],aes(Social,FineLoad)) + geom_boxplot(aes(fill=session)) + geom_jitter(aes(col=session))
print(g1)
# Density plots for the PCA dimensions for each kind of activity
# g1 <- ggplot(noveldata[!is.na(noveldata$Social),],aes(PupilLoadDim)) + geom_density(aes(col=Social))
# print(g1)
# g2 <- ggplot(noveldata[!is.na(noveldata$Social),],aes(EyeMoveFixLoadDim)) + geom_density(aes(col=Social))
# print(g2)
# Another way of seeing this, in the PCA diagram
res.pca = PCA(noveldata[, c(3:6, 13)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=5)
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5, invisible="ind")
res.pca = PCA(noveldata3[, c(3:6, 13)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=5)
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5, invisible="ind")
res.pca = PCA(noveldata4[, c(3:6, 13)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=5)
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5, invisible="ind")

# Comparison against the HMM states of load -- session by session, since the states are different
noveldata3$MMstate <- factor(noveldata3$MMstate)
hmmSocTab <- xtabs(~Social+MMstate, data=noveldata3[!is.na(noveldata3$Social),])
chisq.test(hmmSocTab)
hmmSocTab
chisq.test(hmmSocTab)$residuals
noveldata4$MMstate <- factor(noveldata4$MMstate)
hmmSocTab <- xtabs(~Social+MMstate, data=noveldata4[!is.na(noveldata4$Social),])
chisq.test(hmmSocTab)
hmmSocTab
chisq.test(hmmSocTab)$residuals

```

In the case of the **novel technology**, we see the same trends, but in a slightly less clear manner (but still statistically significant): CLS is high-load, GRP is low-load. The trends in the second session seem less clear than in the first one with novel technology, though. Also similar to the usual technology case, the social level is mainly different in terms of the 2nd dimension (pupil mean vs. fixation).

The HMM states, again, clearly put CLS in mid-high pupil mean or high-load or mid-load states, and GRP more into mid-low pupil or low-load states.

**Comparison between usual and novel technology**: both kinds of sessions are consistently showing how CLS is generally a high-load state, while GRP or IND are lower-load episodes, and that differences are especially seen along the pupil mean dimension of load.


#### Gaze focus dimension

**Note: in the second novel session the gaze pointer seemed to be miscalibrated, so the behavioral results for that session in terms of gaze focus should be taken with a pinch of salt**

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
# FOCUS
# Overall data analysis
#behdata <- loaddata[(!is.na(loaddata$Focus)),]
behdata <- loaddata[((loaddata$CoarseLoad==0 | loaddata$CoarseLoad==4) & !is.na(loaddata$Focus)),]
behdata$Focus <- factor(behdata$Focus)
# chi-squared test and counts/residuals table for main focus of gaze
tabFoc <- table(behdata$CoarseLoad,behdata$Focus)
chisq.test(tabFoc)
tabFoc
chisq.test(tabFoc)$residuals

# Plotting against the FineLoad is not very revealing, as we took extreme values and the averages will always be around the average values!
g1 <- ggplot(loaddata[!is.na(loaddata$Focus),],aes(Focus,FineLoad)) + geom_boxplot(aes(fill=Focus)) + geom_jitter(aes(col=session))
print(g1)
# Density plots for the PCA dimensions for each kind of activity ... not very readable
# g1 <- ggplot(loaddata[!is.na(loaddata$Focus),],aes(PupilLoadDim)) + geom_density(aes(col=Focus))
# print(g1)
# g2 <- ggplot(loaddata[!is.na(loaddata$Focus),],aes(EyeMoveFixLoadDim)) + geom_density(aes(col=Focus))
# print(g2)
# Another way of seeing this, in the PCA diagram
res.pca = PCA(loaddata[, c(3:6, 11)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=5)
#plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5)
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5, invisible="ind")

# Comparison against the HMM states of load
hmmFocTab <- xtabs(~Focus+MMstate, data=loaddata[!is.na(loaddata$Focus),])
chisq.test(hmmFocTab)
hmmFocTab
chisq.test(hmmFocTab)$residuals
```

The overall analysis of **Gaze focus** shows that it is very unlikely to be independent of the cognitive load measures. The residuals (and the boxplots of the fine load) tell us that high-load episodes are more often looking at the FACes of people, while low-load are majoritarily focusing on the student's LAPtops, PAPer elements with exercises, teacher's TCOMPuter or the PRJector or the TABletop (in the novel technology sessions).

The PCA dimensions, however, show how differences are mostly in the variance/saccade dimension (with FAC at the positive side, along wth PRJ) and PAP, TCOMP, LAP in the negative side. This is confirmed by the separation between HMM states in terms of gaze focus: FACes tend to be in high-load states, or mid-high load states; TCOMP is in low-mid fixation state; LAP and PAP tend to be in low-load or low-mid states.

However, let us look at the gaze focus trends differences between the sessions with the usual and novel technologies:

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
# Usual data analysis
#behdata <- usualdata[(!is.na(usualdata$Focus)),]
behdata <- usualdata[((usualdata$CoarseLoad==0 | usualdata$CoarseLoad==4) & !is.na(usualdata$Focus)),]
behdata$Focus <- factor(behdata$Focus)
# chi-squared test and counts/residuals table for main focus of gaze
tabFoc <- table(behdata$CoarseLoad,behdata$Focus)
chisq.test(tabFoc)
tabFoc
chisq.test(tabFoc)$residuals

# Plotting against the FineLoad is not very revealing, as we took extreme values and the averages will always be around the average values!
g1 <- ggplot(usualdata[!is.na(usualdata$Focus),],aes(Focus,FineLoad)) + geom_boxplot(aes(fill=Focus)) + geom_jitter(aes(col=session))
print(g1)
# Density plots for the PCA dimensions for each kind of activity ... not very readable
# g1 <- ggplot(usualdata[!is.na(usualdata$Focus),],aes(PupilLoadDim)) + geom_density(aes(col=Focus))
# print(g1)
# g2 <- ggplot(usualdata[!is.na(usualdata$Focus),],aes(EyeMoveFixLoadDim)) + geom_density(aes(col=Focus))
# print(g2)
# Another way of seeing this, in the PCA diagram
res.pca = PCA(usualdata[, c(3:6, 11)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=5)
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5, invisible="ind")

# Comparison against the HMM states of load
usualdata$Focus <- factor(usualdata$Focus) # We remove nonexistent focus levels
hmmFocTab <- xtabs(~Focus+MMstate, data=usualdata[!is.na(usualdata$Focus),])
chisq.test(hmmFocTab)
hmmFocTab
chisq.test(hmmFocTab)$residuals
```

For the sessions of the **usual technology**, we can see that the main gaze focus seems significantly correlated with the coarse and fine load, with the FACes being the high-load episodes, and LAP, PAP and TCOMP being lower-load. Again, we see how these differences are mostly in the pupil mean (FAC) vs. fixation (LAP, PAP, TCOMP) dimension. The HMM states confirm that FAC tends to be in a high-load pupil mean state, while LAP, PAP tend to be in the low-load state, and TCOMP tends to be in the low-mid fixation-heavy state.

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
# Novel technology analysis
#behdata <- noveldata[(!is.na(noveldata$Focus)),]
behdata <- noveldata[((noveldata$CoarseLoad==0 | noveldata$CoarseLoad==4) & !is.na(noveldata$Focus)),]
behdata3 <- noveldata3[((noveldata3$CoarseLoad==0 | noveldata3$CoarseLoad==4) & !is.na(noveldata3$Focus)),]
behdata4 <- noveldata4[((noveldata4$CoarseLoad==0 | noveldata4$CoarseLoad==4) & !is.na(noveldata4$Focus)),]

behdata$Focus <- factor(behdata$Focus)
behdata3$Focus <- factor(behdata3$Focus)
behdata4$Focus <- factor(behdata4$Focus)

# chi-squared test and counts/residuals table for main focus of gaze
tabFoc <- table(behdata$CoarseLoad,behdata$Focus)
chisq.test(tabFoc)
tabFoc
chisq.test(tabFoc)$residuals

tabFoc3 <- table(behdata3$CoarseLoad,behdata3$Focus)
chisq.test(tabFoc3)
tabFoc3
chisq.test(tabFoc3)$residuals

tabFoc4 <- table(behdata4$CoarseLoad,behdata4$Focus)
chisq.test(tabFoc4)
tabFoc4
chisq.test(tabFoc4)$residuals


# Plotting against the FineLoad is not very revealing, as we took extreme values and the averages will always be around the average values!
g1 <- ggplot(noveldata[!is.na(noveldata$Focus),],aes(Focus,FineLoad)) + geom_boxplot(aes(fill=Focus)) + geom_jitter(aes(col=session))
print(g1)
# Density plots for the PCA dimensions for each kind of activity ... not very readable
# g1 <- ggplot(noveldata[!is.na(noveldata$Focus),],aes(PupilLoadDim)) + geom_density(aes(col=Focus))
# print(g1)
# g2 <- ggplot(noveldata[!is.na(noveldata$Focus),],aes(EyeMoveFixLoadDim)) + geom_density(aes(col=Focus))
# print(g2)
# Another way of seeing this, in the PCA diagram
res.pca = PCA(noveldata[, c(3:6, 11)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=5)
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5, invisible="ind")
res.pca = PCA(noveldata3[, c(3:6, 11)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=5)
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5, invisible="ind")
res.pca = PCA(noveldata4[, c(3:6, 11)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=5)
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5, invisible="ind")

# Comparison against the HMM states of load
noveldata3$Focus <- factor(noveldata3$Focus) # We remove nonexistent focus levels
hmmFocTab <- xtabs(~Focus+MMstate, data=noveldata3[!is.na(noveldata3$Focus),])
chisq.test(hmmFocTab)
hmmFocTab
chisq.test(hmmFocTab)$residuals
noveldata4$Focus <- factor(noveldata4$Focus) # We remove nonexistent focus levels
hmmFocTab <- xtabs(~Focus+MMstate, data=noveldata4[!is.na(noveldata4$Focus),])
chisq.test(hmmFocTab)
hmmFocTab
chisq.test(hmmFocTab)$residuals
```

In the case of the **novel technology** the trends are somewhat similar, substituting the laptop with the TABletops: FACes tend to be most of the high-load episodes, while TAB (and to a lesser extent, PRJector) is the main focus in low-load episodes. As in previous analyses, we can see how the two sessions are different in their distributions along the two dimensions (with the second novel session being more stretched in the saccade/variation dimension -- maybe due to the miscalibration noted above?).

The separation provided by the HMM states is somewhat confirming this: FAC tends to be more on the high, mid-high or mid load states, while TAB are in the low or mid-low load states.

**Comparison between novel and usual technologies**: the results are largely compatible, if we account for the fact that different technologies account for different gaze focuses: the FACes of student are invariable classified in the high-load episodes and states, while the technology itself (LAP or TAB or TCOMP) tends to be more often the focus in the low-load episodes/states.


Similar conclusions can be reached by using a **composite variable of Activity/Social and Activity/Social/Focus**

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
data <- loaddata[complete.cases(loaddata[,c("Activity","Social","Focus")]) & (loaddata$CoarseLoad==4 | loaddata$CoarseLoad==0),]

data$ActSocial <- factor(paste0(data$Activity,data$Social))
actsocTab <- xtabs(~ActSocial+CoarseLoad, data=data)
chisq.test(actsocTab)
actsocTab
chisq.test(actsocTab)$residuals

data$ActSocialFoc <- factor(paste0(data$Activity,data$Social,data$Focus))
actsocfocTab <- xtabs(~ActSocialFoc+CoarseLoad, data=data)
chisq.test(actsocfocTab)
actsocfocTab
chisq.test(actsocfocTab)$residuals


```



### E: Session-level analysis and comparison

There are several ways in which we can compare the overall load and experience of orchestration among sessions:

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
# Compare subjective ratings and comments
setwd(paste(rootdir,"/data/study3",sep=""))

sessionusual <- read.csv("ISL2014BASELINE-sessionratings.csv", sep=";")
sessionnovel <- read.csv("ISL2015NOVEL-sessionratings.csv", sep=",")
rbind.all.columns <- function(x, y) {
 
    x.diff <- setdiff(colnames(x), colnames(y))
    y.diff <- setdiff(colnames(y), colnames(x))
 
    x[, c(as.character(y.diff))] <- NA
 
    y[, c(as.character(x.diff))] <- NA
 
    return(rbind(x, y))
}
sessiondata <- rbind.all.columns(sessionusual,sessionnovel)

print(sessiondata[,c("Session","Subj.Mental.Effort","Subj.Difficulty")])
```

In most cases the teacher assessed the overall load as involving `some mental effort' (6 in a scale of 1-9 in the standard subjective mental effort scale), with the exception of the first novel technology session, which was rated 7 (high mental effort). The teacher, however, considered the second usual session as slightly more difficult to manage (6 vs. 5 out of 9), and viceversa for the novel technology sessions (6 in the first one, 5 in the second one). 

This perception can be expanded by looking at the teacher's responses to the TLX questionnaire about the sessions workload: 

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=3, fig.width=8}
print(sessiondata[,2:14])

sessiondata$SessionType <- as.factor(c("Usual","Usual","Novel","Novel"))
sessiondata$Total.Mental <- sessiondata$Value.Mental.Demand * sessiondata$Importance.Mental.Demand
sessiondata$Total.Physical <- sessiondata$Value.Physical.Demand * sessiondata$Importance.Physical.Demand
sessiondata$Total.Temporal <- sessiondata$Value.Temporal.Demand * sessiondata$Importance.Temporal.Demand
sessiondata$Total.Performance <- sessiondata$Value.Performance * sessiondata$Importance.Performance
sessiondata$Total.Effort <- sessiondata$Value.Effort * sessiondata$Importance.Effort
sessiondata$Total.Frustration <- sessiondata$Value.Frustration * sessiondata$Importance.Frustration

qplot(sessiondata$Session,sessiondata$TLX.Total,fill=sessiondata$SessionType)+geom_bar(stat = "identity")

# We see the averages between usual and novel technologies
aggregate(. ~ SessionType, data=sessiondata[,c(23:29)], FUN=mean)
```

In all cases responses were quite similar (overall workload scores of 48 to 62 out of 100). However, by looking at the scores and weighting of the different workload components (mental, temporal or physical demands, performance, effort and frustration), we see that in session 2 the value and weighting of the 'frustration' component were much higher than in session 1; conversely, the novel technology sessions were quite similar, except for the frustration which was very noticeably decreased in the last session.

If we compare the average scores of the usual and novel technology sessions, we see that, while their average loads are comparable (0.2% difference in favor of the usual technology), the workload experiences were quite different: Usual sessions involved more load from mental demand, effort and frustration; novel technology sessions involved more load from temporal demand.

```{r,message=FALSE}
# We print the especially difficult moment remarks
print("Especially difficult -- Usual")
print(as.character(sessiondata[sessiondata$SessionType=="Usual",17]))
print("Especially difficult -- Novel")
print(as.character(sessiondata[sessiondata$SessionType=="Novel",17]))

# We print the especially easy moment remarks
print("Especially easy -- Usual")
print(as.character(sessiondata[sessiondata$SessionType=="Usual",18]))
print("Especially easy -- Novel")
print(as.character(sessiondata[sessiondata$SessionType=="Novel",18]))
```

The qualitative (open) responses about self-perceived high-load episodes were also quite similar in each condition, but the emphases varied from the usual to the novel technology sessions: in the usual technology sessions the teacher was focusing more on students progress, understanding, and in the second session, some disciplinary aspects; in the novel technology the focus was more on the temporal demands, technical glitches and other concrete doubts about the game.


We can also, however, look at the subjective ratings and remarks from the stimulated recall interviews:

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=3, fig.width=8}
srdata[srdata$session==sessions[1] | srdata$session==sessions[2],"SessionType"] <- "Usual"
srdata[srdata$session==sessions[3] | srdata$session==sessions[4],"SessionType"] <- "Novel"
srdata$SessionType <- factor(srdata$SessionType)

qplot(session,Subjective.Value, data=srdata, geom="boxplot", fill=session)+geom_jitter()

codes <- flattenCodeData(srdata,codecol = 6,additionalcol = c(3,7,8))

qplot(Code,data=codes,geom="bar",fill=SessionType)
```

Interesingly, we can see how the selected episodes from the novel technology sessions were in general rated as higher mental effort by the teacher during the interview. We see that some of the notions mentioned are common to both kinds of sessions (Assesment, Modelling, Following progress) while others are specific of the activities being held, especially in the novel sessions (Guiding, Frustration, Anticipation, Collaboration, and Game-specific remarks)


To triangulate this perception with more objective data, we can also look at the eye-tracking measures of load across sessions and session types.


```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
loaddata[loaddata$session==sessions[1] | loaddata$session==sessions[2],"SessionType"] <- "Usual"
loaddata[loaddata$session==sessions[3] | loaddata$session==sessions[4],"SessionType"] <- "Novel"
loaddata$SessionType <- factor(loaddata$SessionType)

# Plotting the FineLoad of each session
g1 <- ggplot(loaddata,aes(session,FineLoad)) + geom_boxplot(aes(fill=SessionType))
print(g1)
g1 <- ggplot(loaddata,aes(FineLoad)) + geom_density(aes(col=session))
print(g1)

# Plotting against the PCA and HMM dimensions
# g1 <- ggplot(loaddata,aes(PupilLoadDim)) + geom_density(aes(col=session))
# print(g1)
# g1 <- ggplot(loaddata,aes(EyeMoveFixLoadDim)) + geom_density(aes(col=session))
# print(g1)

#by session
loaddata$session <- factor(loaddata$session)
res.pca = PCA(loaddata[, c(3:6, 1)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=5)
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5, invisible="ind")
#by session type
res.pca = PCA(loaddata[, c(3:6, 36)], scale.unit=TRUE, ncp=5, graph=F, quali.sup=5)
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=5, invisible="ind")


# Comparison against the HMM states of load -- it may not make much sense since states are session-dependent
# We aggregate the levels with similar labels
loaddata$MMstateType <- loaddata$MMstate
levels(loaddata$MMstateType) <- c("Low","HiSacVar","MidLow",
                              "Hi", "MidHi", "MidLow",
                              "Mid","MidLow","MidHi","Hi")

hmmSessTab <- xtabs(~session+MMstate, data=loaddata)
chisq.test(hmmSessTab)
hmmSessTab
chisq.test(hmmSessTab)$residuals

hmmSessTab <- xtabs(~SessionType+MMstateType, data=loaddata)
chisq.test(hmmSessTab)
hmmSessTab
chisq.test(hmmSessTab)$residuals
```

Interestingly, looking at the coarse and fine load distributions, although differences are not very large, there is a noticeable increase of average load indices in the fourth (second novel) session -- contrary to the teacher's subjective perception. These differences seem to be largely on the pupil mean vs. long fixation dimension (long fixations being higher in the first novel session and pupil diameter being larger in the the second novel one); on average, the novel sessions seemed to have higher saccadic/pupil variation load.

Also, from the HMM states (or, rather, the different type of states), we see that the usual sessions had larger number of Low and Hi state episodes, while the novel sessions had more mid-low, mid and mid-hi state episodes (not a very clear outcome, but the distribution of novel session episodes also seems slanted towards the higher end).


Finally, another way of comparing the sessions is through the (normalized) median values of each of the sessions, upon which the coarse load index was calculated:

```{r, message=FALSE, warning=FALSE}
#median values for each session
#aggregate(cbind(value.Mean.norm,value.SD.norm,value.Fix.norm,value.Sac.norm)~session,data = loaddata, FUN = median)
library(reshape)

data <- aggregateEpisodeData(sessions, datadir=paste(rootdir,"/data/study3",sep=""), initendtimes=NULL, SEPARATOR=";") # For this study the raw data is semicolon-separated, at least the fixation/saccades!
data <- data[,c(1:5,12)] # We select only the load-related metrics
data$Session <- data$session

# This dataframe will contain the data with the added Load Index data, calculated with the (normalized) median values of session 2
loaddata2 <- data.frame()

# We calculate the load index, considering normalized median of session 2 values for the median cut
loaddata2 <- calculateLoadIndexOtherSessionNormalized(data, refsession="ISL2014BASELINE-Session1-eyetracking", meanlabel="value.Mean", sdlabel="value.SD", fixlabel="value.Fix", saclabel="value.Sac")

# Average load index when using the first session as a reference
aggregate(Load~Session,data=loaddata2,mean)

# Now, loaddata will contain the data to be summarized/visualized
# We eliminate the NAs
#loaddata2 <- loaddata2[complete.cases(loaddata2),]
# We do a basic histogram of the amount episodes regarding their Load Index of each session, 
# using its session median to perform the cut (and normalized by the number of episodes in each session)
loadtabSelf2 <- table(loaddata2$Load, loaddata2$Session)
countsDataSelf2 <- melt(loadtabSelf2, varnames=c("Load","Session"))
countsDataSelf2$num.Episodes <- numeric(nrow(countsDataSelf2))
for(session in sessions){
     countsDataSelf2[countsDataSelf2$Session == session,"num.Episodes"] <- sum(countsDataSelf2[countsDataSelf2$Session == session , "value"])
}
# We change the values of the session to something shorter, for aesthetic reasons
#countsDataSelf2$Session <- mapvalues(countsDataSelf2$Session, from = sessions, to = c("Session 1", "Session 2"))
# We draw the plot of count proportions for the load index
ggplot(countsDataSelf2,aes(x=Load,y=value/num.Episodes,fill=Session))+
    geom_bar(stat="identity",position="dodge")+
    theme(axis.text=element_text(size=15),
        axis.title=element_text(size=15),
        legend.text=element_text(size=15),
        legend.title=element_text(size=15))+
    xlab("Load indices calculated using (normalized)\nmedians for session 2 in both sessions")+
    ylab("Proportions of the load indices")

# We check whether the two session distributions are significantly different
chisq.test(loadtabSelf2)
```

In this case, the average coarse load index values when considering the first session as a reference, paint a picture similar to the overall subjective ratings: the second usual session was more load than the first, and the first novel one was even more load, due to the novelty of the situation. The last session with novel technology was comparable to the first one, once the teacher had got used to the situation and the technology.


Something else we can try to see is whether the proportions of different video codes vary a lot from session to session:

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}

sessActTab <- xtabs(~session+Activity, data=loaddata)
chisq.test(sessActTab)
sessActTab
chisq.test(sessActTab)$residuals

sessSocTab <- xtabs(~session+Social, data=loaddata)
chisq.test(sessSocTab)
sessSocTab
chisq.test(sessSocTab)$residuals

sessFocTab <- xtabs(~session+Focus, data=loaddata)
chisq.test(sessFocTab)
sessFocTab
chisq.test(sessFocTab)$residuals


```

We plot many of the overall results side by side:

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE, fig.height=5, fig.width=5}
# Summarizing function
## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
    library(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
      .fun = function(xx, col) {
        c(N    = length2(xx[[col]], na.rm=na.rm),
          mean = mean   (xx[[col]], na.rm=na.rm),
          sd   = sd     (xx[[col]], na.rm=na.rm)
        )
      },
      measurevar
    )

    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    return(datac)
}


sessiondata$sessionkind <- ifelse((sessiondata$Session==sessions[1] | sessiondata$Session==sessions[2]), "Usual", "Novel")
loaddata$sessionkind <- ifelse((loaddata$session==sessions[1] | loaddata$session==sessions[2]), "Usual", "Novel")
loaddata2$sessionkind <- ifelse((loaddata2$Session==sessions[1] | loaddata2$Session==sessions[2]), "Usual", "Novel")

levels(sessiondata$Session) <- c("Session1","Session2","Session3","Session4")
levels(loaddata$session) <- c("Session1","Session2","Session3","Session4")

loaddata2$Session <- as.factor(loaddata2$Session)
loaddata2$session <- as.factor(loaddata2$session)
levels(loaddata2$Session) <- c("Session1","Session2","Session3","Session4")
levels(loaddata2$session) <- c("Session1","Session2","Session3","Session4")

print(str(loaddata2))

#qplot(sessiondata$Session,sessiondata$TLX.Total,fill=sessiondata$SessionType)+geom_bar(stat = "identity")
agTLX <- aggregate(TLX.Total~Session+sessionkind, data=sessiondata, mean)
agTLX

ggplot(agTLX, aes(x=Session, y=TLX.Total, fill=sessionkind)) + 
     geom_bar(position=position_dodge(), stat="identity") +
     ggtitle("Overall subjective workload (NASA TLX)")

agMental <- aggregate(Subj.Mental.Effort~Session+sessionkind, data=sessiondata, mean)
agMental

ggplot(agMental, aes(x=Session, y=Subj.Mental.Effort, fill=sessionkind)) + 
     geom_bar(position=position_dodge(), stat="identity") +
     ggtitle("Overall subjective estimation of mental effort")


agDifficulty <- aggregate(Subj.Difficulty~Session+sessionkind, data=sessiondata, mean)
agDifficulty

ggplot(agDifficulty, aes(x=Session, y=Subj.Difficulty, fill=sessionkind)) + 
     geom_bar(position=position_dodge(), stat="identity") +
     ggtitle("Overall subjective estimation of session difficulty")

#names(loaddata)
agFineLoad <- aggregate(FineLoad~session, data=loaddata, mean)
agFineLoad

sumFine <- summarySE(loaddata, measurevar="FineLoad", groupvars=c("session","sessionkind"))
sumFine
ggplot(sumFine, aes(x=session, y=FineLoad, fill=sessionkind)) + 
     geom_bar(position=position_dodge(), stat="identity") +
     geom_errorbar(aes(ymin=FineLoad-ci, ymax=FineLoad+ci),
                   width=.2,                    # Width of the error bars
                   position=position_dodge(.9)) + 
     ggtitle("Fine load index (eyetracking)")

loaddata2 <- loaddata2[complete.cases(loaddata2$Load),]
agLoadOther <- aggregate(Load~Session,data=loaddata2,mean)
agLoadOther

sumOther <- summarySE(loaddata2, measurevar="Load", groupvars=c("Session","sessionkind"))
sumOther
ggplot(sumOther, aes(x=Session, y=Load, fill=sessionkind)) + 
     geom_bar(position=position_dodge(), stat="identity") +
     geom_errorbar(aes(ymin=Load-ci, ymax=Load+ci),
                   width=.2,                    # Width of the error bars
                   position=position_dodge(.9)) + 
     ggtitle("Coarse load index, norm. agnst session 1 (eyetrack)")


agSacVar <- aggregate(SacVarLoadDim~session, data=loaddata, mean)
agSacVar

sumSac <- summarySE(loaddata, measurevar="SacVarLoadDim", groupvars=c("session","sessionkind"))
sumSac
ggplot(sumSac, aes(x=session, y=SacVarLoadDim, col=sessionkind, fill=sessionkind)) + 
     #geom_bar(position=position_dodge(), stat="identity") +
    geom_point() +
     geom_errorbar(aes(ymin=SacVarLoadDim-ci, ymax=SacVarLoadDim+ci),
                   width=.2,                    # Width of the error bars
                   position=position_dodge(.9)) + 
     ggtitle("First PCA load dimension (pupil variance, saccade speed)")

agPupFix <- aggregate(PupilVsFixLoadDim~session, data=loaddata, mean)
agPupFix

sumPup <- summarySE(loaddata, measurevar="PupilVsFixLoadDim", groupvars=c("session","sessionkind"))
sumPup
ggplot(sumPup, aes(x=session, y=PupilVsFixLoadDim, col=sessionkind, fill=sessionkind)) + 
     #geom_bar(position=position_dodge(), stat="identity") +
    geom_point() +
     geom_errorbar(aes(ymin=PupilVsFixLoadDim-ci, ymax=PupilVsFixLoadDim+ci),
                   width=.2,                    # Width of the error bars
                   position=position_dodge(.9)) + 
     ggtitle("Second PCA load dimension (pupil mean vs. long fixations)")


# multiplot(p1, p2, p3, p4, p5, p6, cols=6)
```



```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
# We come to the root folder, for the next study
setwd(rootdir)
```
